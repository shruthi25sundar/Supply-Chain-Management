{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d9b16e8-270c-4400-a05b-8ff32a69a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84b827ed-d3b7-47fc-ad29-b48a15dcba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"/workspaces/Supply-Chain-Management/Data/supplier_contracts_dataset.csv\")\n",
    "df = df.replace({np.nan: None})\n",
    "# Rename columns to remove spaces\n",
    "# df.columns = [col.replace(' ', '_') for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb664984-a7ef-4200-b6b5-3e4038f6141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = df.columns.str.lower()\n",
    "# df.to_csv(r\"/workspaces/Supply-Chain-Management/Data/supplier_contracts_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba4aa868-e50f-42a6-83c1-edad05481382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['supplier_id', 'supplier_name', 'supplier_type', 'risk_level',\n",
       "       'compliance_issues', 'key_terms', 'past_performance',\n",
       "       'negotiate_recommendation', 'supply_chain_disruption',\n",
       "       'quality_metrics', 'cost_metrics'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0882f38e-bfb0-4a6d-8e86-b800e487995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.rename(columns={'supplier_id':'id'})\n",
    "# # Convert only the relevant text-based fields to string\n",
    "text_fields = ['supplier_name', 'supplier_type', 'risk_level',\n",
    "       'compliance_issues', 'key_terms', 'past_performance',\n",
    "       'negotiate_recommendation', 'supply_chain_disruption',\n",
    "       'quality_metrics', 'cost_metrics']\n",
    "\n",
    "# Ensure the specified text fields are strings\n",
    "for field in text_fields:\n",
    "    df[field] = df[field].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72f92f7-1a8a-4269-8b50-73344ed859c7",
   "metadata": {},
   "source": [
    "**MINSEARCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6183ad8-eecb-4b0c-89d5-88e50fcd868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = df.columns.str.lower()\n",
    "# df.to_csv(r\"/workspaces/Supply-Chain-Management/Data/supplier_contracts_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52a10368-dd4e-4f83-b5c1-0188e0a964d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300178f7-1cb6-46de-8d96-5375400164ea",
   "metadata": {},
   "source": [
    "Get top 10 list of high risk level contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43b9cd5b-c404-476c-9390-2bf2f2dc600f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'S2482', 'supplier_name': 'Supplier 2482', 'supplier_type': 'Service Provider', 'risk_level': 'High', 'compliance_issues': 'Non-Compliance with Standards', 'key_terms': '45-day payment, 10-day delivery', 'past_performance': 'Poor', 'negotiate_recommendation': 'Include penalty clauses for late delivery, Include compliance monitoring, Adjust delivery schedules', 'supply_chain_disruption': 'No', 'quality_metrics': '2.99% defect rate, Meets standards', 'cost_metrics': '$60.18/unit, $5539.99 total cost'}\n",
      "{'id': 'S2481', 'supplier_name': 'Supplier 2481', 'supplier_type': 'Manufacturer', 'risk_level': 'High', 'compliance_issues': 'Substandard Quality', 'key_terms': '30-day payment, 5-day delivery', 'past_performance': 'Good', 'negotiate_recommendation': 'Include penalty clauses for late delivery, Seek alternative suppliers, Adjust delivery schedules', 'supply_chain_disruption': 'No', 'quality_metrics': '1.04% defect rate, Meets standards', 'cost_metrics': '$66.06/unit, $5158.25 total cost'}\n",
      "{'id': 'S2480', 'supplier_name': 'Supplier 2480', 'supplier_type': 'Distributor', 'risk_level': 'High', 'compliance_issues': 'Late Delivery', 'key_terms': '30-day payment, 5-day delivery', 'past_performance': 'Poor', 'negotiate_recommendation': 'Adjust delivery schedules, Include compliance monitoring, Include penalty clauses for late delivery', 'supply_chain_disruption': 'Yes', 'quality_metrics': '3.96% defect rate, Meets standards', 'cost_metrics': '$67.89/unit, $5083.32 total cost'}\n",
      "{'id': 'S2476', 'supplier_name': 'Supplier 2476', 'supplier_type': 'Service Provider', 'risk_level': 'High', 'compliance_issues': 'Late Delivery', 'key_terms': '60-day payment, 7-day delivery', 'past_performance': 'Fair', 'negotiate_recommendation': 'Include compliance monitoring, Include penalty clauses for late delivery, Seek alternative suppliers', 'supply_chain_disruption': 'No', 'quality_metrics': '3.92% defect rate, Meets standards', 'cost_metrics': '$58.74/unit, $5201.92 total cost'}\n",
      "{'id': 'S2475', 'supplier_name': 'Supplier 2475', 'supplier_type': 'Service Provider', 'risk_level': 'High', 'compliance_issues': 'None', 'key_terms': '30-day payment, 5-day delivery', 'past_performance': 'Poor', 'negotiate_recommendation': 'Adjust delivery schedules, Include compliance monitoring, Include penalty clauses for late delivery', 'supply_chain_disruption': 'Yes', 'quality_metrics': '2.36% defect rate, Meets standards', 'cost_metrics': '$56.24/unit, $5756.96 total cost'}\n",
      "{'id': 'S2471', 'supplier_name': 'Supplier 2471', 'supplier_type': 'Distributor', 'risk_level': 'High', 'compliance_issues': 'Substandard Quality', 'key_terms': '45-day payment, 10-day delivery', 'past_performance': 'Poor', 'negotiate_recommendation': 'Include penalty clauses for late delivery, Include compliance monitoring, Seek alternative suppliers', 'supply_chain_disruption': 'Yes', 'quality_metrics': '4.0% defect rate, Meets standards', 'cost_metrics': '$63.12/unit, $5305.8 total cost'}\n",
      "{'id': 'S2470', 'supplier_name': 'Supplier 2470', 'supplier_type': 'Retailer', 'risk_level': 'High', 'compliance_issues': 'None', 'key_terms': '60-day payment, 7-day delivery', 'past_performance': 'Fair', 'negotiate_recommendation': 'Include compliance monitoring, Include penalty clauses for late delivery, Seek alternative suppliers', 'supply_chain_disruption': 'No', 'quality_metrics': '3.64% defect rate, Meets standards', 'cost_metrics': '$63.19/unit, $5607.82 total cost'}\n",
      "{'id': 'S0032', 'supplier_name': 'Supplier 32', 'supplier_type': 'Retailer', 'risk_level': 'High', 'compliance_issues': 'Non-Compliance with Standards', 'key_terms': '60-day payment, 7-day delivery', 'past_performance': 'Excellent', 'negotiate_recommendation': 'Include penalty clauses for late delivery, Seek alternative suppliers, Adjust delivery schedules', 'supply_chain_disruption': 'No', 'quality_metrics': '1.48% defect rate, Meets standards', 'cost_metrics': '$56.9/unit, $5324.41 total cost'}\n",
      "{'id': 'S0028', 'supplier_name': 'Supplier 28', 'supplier_type': 'Retailer', 'risk_level': 'High', 'compliance_issues': 'Late Delivery', 'key_terms': '30-day payment, 5-day delivery', 'past_performance': 'Fair', 'negotiate_recommendation': 'Seek alternative suppliers, Include compliance monitoring, Include penalty clauses for late delivery', 'supply_chain_disruption': 'No', 'quality_metrics': '3.01% defect rate, Meets standards', 'cost_metrics': '$62.42/unit, $5753.75 total cost'}\n",
      "{'id': 'S0026', 'supplier_name': 'Supplier 26', 'supplier_type': 'Distributor', 'risk_level': 'High', 'compliance_issues': 'Late Delivery', 'key_terms': '30-day payment, 5-day delivery', 'past_performance': 'Excellent', 'negotiate_recommendation': 'Include compliance monitoring, Seek alternative suppliers, Adjust delivery schedules', 'supply_chain_disruption': 'Yes', 'quality_metrics': '4.27% defect rate, Meets standards', 'cost_metrics': '$65.79/unit, $5685.45 total cost'}\n"
     ]
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "# Create an index\n",
    "index = minsearch.Index(\n",
    "    text_fields=text_fields,\n",
    "    keyword_fields=[]\n",
    ")\n",
    "\n",
    "# Fit the index with the documents\n",
    "index.fit(documents)\n",
    "\n",
    "# Example search query\n",
    "query = \"high risk level\"\n",
    "results = index.search(query, num_results=10)\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c74c41-7f4e-4e5b-b043-cb561d3545ff",
   "metadata": {},
   "source": [
    "Get the Contract types that has high risk and their count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "884b4c83-5084-4261-8294-d96ccc7d5f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each supplier type with high risk level:\n",
      "Retailer: 197\n",
      "Distributor: 198\n",
      "Manufacturer: 201\n",
      "Service Provider: 219\n"
     ]
    }
   ],
   "source": [
    "import minsearch\n",
    "from collections import Counter\n",
    "# Create an index\n",
    "index = minsearch.Index(\n",
    "    text_fields=text_fields,\n",
    "    keyword_fields=['risk_level']\n",
    ")\n",
    "\n",
    "# Fit the index with the documents\n",
    "index.fit(documents)\n",
    "\n",
    "# Perform the search for high-risk level contracts\n",
    "filter_dict = {'risk_level': 'High'}\n",
    "results = index.search(query='high risk level', filter_dict=filter_dict, num_results=len(documents))\n",
    "\n",
    "# Extract and print contract types with high risk level\n",
    "high_risk_contract_types = [result['supplier_type'] for result in results]\n",
    "\n",
    "# Count the occurrences of each contract type\n",
    "contract_type_counts = Counter(high_risk_contract_types)\n",
    "\n",
    "# Print the count of each contract type\n",
    "print(\"Count of each supplier type with high risk level:\")\n",
    "for contract_type, count in contract_type_counts.items():\n",
    "    print(f\"{contract_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cba7a3d-375a-446f-99f1-784b93b04861",
   "metadata": {},
   "source": [
    "**GROQ API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4215677c-21b6-421a-a293-51059466e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55dcc07c-a334-4093-a931-a8d36579dc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supplier 6:\n",
      "- Supplier Type: Manufacturer\n",
      "- Quality Metrics: 3.43% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: Yes\n",
      "- Negotiation Recommendations: Seek alternative suppliers, Include penalty clauses for late delivery, Adjust delivery schedules\n",
      "\n",
      "Supplier 8:\n",
      "- Supplier Type: Retailer\n",
      "- Quality Metrics: 4.38% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: Yes\n",
      "- Negotiation Recommendations: Include penalty clauses for late delivery, Seek alternative suppliers, Adjust delivery schedules\n",
      "\n",
      "Supplier 12:\n",
      "- Supplier Type: Distributor\n",
      "- Quality Metrics: 3.84% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: Yes\n",
      "- Negotiation Recommendations: Include compliance monitoring, Include penalty clauses for late delivery, Seek alternative suppliers\n",
      "\n",
      "Supplier 14:\n",
      "- Supplier Type: Service Provider\n",
      "- Quality Metrics: 2.45% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: Yes\n",
      "- Negotiation Recommendations: Seek alternative suppliers, Adjust delivery schedules, Include compliance monitoring\n",
      "\n",
      "Supplier 15:\n",
      "- Supplier Type: Distributor\n",
      "- Quality Metrics: 1.81% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: No\n",
      "- Negotiation Recommendations: Seek alternative suppliers, Adjust delivery schedules, Include penalty clauses for late delivery\n",
      "\n",
      "Supplier 26:\n",
      "- Supplier Type: Distributor\n",
      "- Quality Metrics: 4.27% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: Yes\n",
      "- Negotiation Recommendations: Include compliance monitoring, Seek alternative suppliers, Adjust delivery schedules\n",
      "\n",
      "Supplier 28:\n",
      "- Supplier Type: Retailer\n",
      "- Quality Metrics: 3.01% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: No\n",
      "- Negotiation Recommendations: Seek alternative suppliers, Include compliance monitoring, Include penalty clauses for late delivery\n",
      "\n",
      "Supplier 32:\n",
      "- Supplier Type: Retailer\n",
      "- Quality Metrics: 1.48% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: No\n",
      "- Negotiation Recommendations: Include penalty clauses for late delivery, Seek alternative suppliers, Adjust delivery schedules\n",
      "\n",
      "Supplier 38:\n",
      "- Supplier Type: Retailer\n",
      "- Quality Metrics: 4.68% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: Yes\n",
      "- Negotiation Recommendations: Seek alternative suppliers, Adjust delivery schedules, Include penalty clauses for late delivery\n",
      "\n",
      "Supplier 40:\n",
      "- Supplier Type: Retailer\n",
      "- Quality Metrics: 1.76% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: No\n",
      "- Negotiation Recommendations: Include penalty clauses for late delivery, Include compliance monitoring, Adjust delivery schedules\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to perform the search on supplier contracts based on query\n",
    "\n",
    "def search(query, filter_dict=None, max_results=10):\n",
    "    # Filter the DataFrame based on risk level (if provided)\n",
    "    if filter_dict:\n",
    "        filtered_df = df[df['risk_level'] == filter_dict.get('risk_level', '')]\n",
    "    else:\n",
    "        filtered_df = df\n",
    "    # Convert the filtered data to a list of dictionaries and limit the number of results\n",
    "    results = filtered_df.to_dict(orient='records')[:max_results]\n",
    "    return results\n",
    "\n",
    "# Function to build a clearer prompt for Groq API\n",
    "def build_clear_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context += (\n",
    "            f\"- **Supplier_Type**: {doc['supplier_type']}\\n\"\n",
    "            f\"  **Supplier_Name**: {doc['supplier_name']}\\n\"\n",
    "            f\"  **Risk_Level**: {doc['risk_level']}\\n\"\n",
    "            f\"  **Compliance_Issues**: {doc['compliance_issues']}\\n\"\n",
    "            f\"  **Key_Terms**: {doc['key_terms']}\\n\"\n",
    "            f\"  **Negotiate_Recommendation**: {doc['negotiate_recommendation']}\\n\"\n",
    "            f\"  **Quality_Metrics**: {doc['quality_metrics']}\\n\"\n",
    "            f\"  **Past_Performance**: {doc['past_performance']}\\n\"\n",
    "            f\"  **Supply_Chain_Disruption**: {doc['supply_chain_disruption']}\\n\"\n",
    "            f\"  **Cost_Metrics**: {doc['cost_metrics']}\\n\\n\"\n",
    "        )\n",
    "    \n",
    "    prompt = (\n",
    "        f\"QUESTION: {query}\\n\\n\"\n",
    "        f\"CONTEXT:\\n{context}\"\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Function to call the LLM (Groq API)\n",
    "def llm(prompt, model='Llama3-groq-70b-8192-tool-use-preview'):\n",
    "    # Assuming client is the Groq API client instance\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Function to perform the full RAG (Retrieve and Generate) process\n",
    "def rag(query, model='Llama3-groq-70b-8192-tool-use-preview'):\n",
    "    # Search for high-risk contracts (you can modify filter_dict based on needs)\n",
    "    search_results = search(query, filter_dict={'risk_level': 'High'})\n",
    "    \n",
    "    # Build the prompt using the search results\n",
    "    prompt = build_clear_prompt(query, search_results)\n",
    "    \n",
    "    # Get the LLM response based on the prompt\n",
    "    answer = llm(prompt, model=model)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "question = \"Give supplier types, quality metrics, supply chain disruptions, and their negotiation recommendations for high-risk contracts\"\n",
    "answer = rag(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da304f86-6d92-490a-8769-2aa75162d14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Risk-Based Queries\n",
      "Based on the provided data, the suppliers with the most non-compliance issues, regardless of risk level, are:\n",
      "\n",
      "1. Supplier 6 (Manufacturer) - Non-Compliance with Standards\n",
      "2. Supplier 8 (Retailer) - Non-Compliance with Standards\n",
      "3. Supplier 12 (Distributor) - Substandard Quality\n",
      "4. Supplier 14 (Service Provider) - Non-Compliance with Standards\n",
      "5. Supplier 15 (Distributor) - Non-Compliance with Standards\n",
      "6. Supplier 26 (Distributor) - Late Delivery\n",
      "7. Supplier 28 (Retailer) - Late Delivery\n",
      "8. Supplier 32 (Retailer) - Non-Compliance with Standards\n",
      "9. Supplier 38 (Retailer) - Late Delivery\n",
      "10. Supplier 40 (Retailer) - Non-Compliance with Standards\n",
      "\n",
      "## Compliance & Legal Queries:\n",
      "Based on the provided data, the suppliers where compliance monitoring is recommended are:\n",
      "\n",
      "1. Supplier 12\n",
      "2. Supplier 40\n",
      "\n",
      "## Cost and Financial Metrics:\n",
      "Supplier 6, Supplier 8, Supplier 12, Supplier 14, Supplier 15, Supplier 26, Supplier 28, Supplier 32, Supplier 38, and Supplier 40 are classified as high-risk suppliers.\n",
      "\n",
      "## Contractual Terms and Recommendations:\n",
      "Based on the provided data, the suppliers with penalty clauses for late delivery in their contracts are:\n",
      "\n",
      "1. Supplier 6 (Manufacturer) - High risk level, with a 3.43% defect rate and a total cost of $6771.24.\n",
      "2. Supplier 8 (Retailer) - High risk level, with a 4.38% defect rate and a total cost of $6727.62.\n",
      "3. Supplier 12 (Distributor) - High risk level, with a 3.84% defect rate and a total cost of $5753.9.\n",
      "4. Supplier 14 (Service Provider) - High risk level, with a 2.45% defect rate and a total cost of $6924.27.\n",
      "5. Supplier 15 (Distributor) - High risk level, with a 1.81% defect rate and a total cost of $5844.03.\n",
      "6. Supplier 26 (Distributor) - High risk level, with a 4.27% defect rate and a total cost of $5685.45.\n",
      "7. Supplier 28 (Retailer) - High risk level, with a 3.01% defect rate and a total cost of $5753.75.\n",
      "8. Supplier 32 (Retailer) - High risk level, with a 1.48% defect rate and a total cost of $5324.41.\n",
      "9. Supplier 38 (Retailer) - High risk level, with a 4.68% defect rate and a total cost of $6368.93.\n",
      "10. Supplier 40 (Retailer) - High risk level, with a 1.76% defect rate and a total cost of $6361.98.\n",
      "\n",
      "The associated risks for these suppliers include non-compliance with standards, late delivery, and substandard quality.\n",
      "\n",
      "## Supplier Relationship Queries:\n",
      "The relationship metrics for suppliers with the best past performance scores are as follows:\n",
      "\n",
      "1. **Supplier 14**: Excellent past performance, 2.45% defect rate, $69.82/unit, $6924.27 total cost\n",
      "2. **Supplier 26**: Excellent past performance, 4.27% defect rate, $65.79/unit, $5685.45 total cost\n",
      "3. **Supplier 32**: Excellent past performance, 1.48% defect rate, $56.9/unit, $5324.41 total cost\n",
      "4. **Supplier 38**: Excellent past performance, 4.68% defect rate, $57.93/unit, $6368.93 total cost\n",
      "5. **Supplier 40**: Excellent past performance, 1.76% defect rate, $66.89/unit, $6361.98 total cost\n",
      "\n",
      "## Opportunity and Innovation Queries:\n",
      "Based on the provided data, the suppliers with innovative solutions despite having poor quality metrics are:\n",
      "\n",
      "1. Supplier 8: This supplier has a high risk level, non-compliance with standards, and a 4.38% defect rate, but they have a good past performance and are experiencing supply chain disruptions.\n",
      "\n",
      "2. Supplier 14: This supplier also has a high risk level, non-compliance with standards, and a 2.45% defect rate. However, they have an excellent past performance and are experiencing supply chain disruptions.\n",
      "\n",
      "3. Supplier 32: This supplier has a high risk level, non-compliance with standards, and a 1.48% defect rate. They have an excellent past performance and are not experiencing any supply chain disruptions.\n",
      "\n",
      "4. Supplier 40: This supplier has a high risk level, non-compliance with standards, and a 1.76% defect rate. They have an excellent past performance and are not experiencing any supply chain disruptions.\n",
      "\n",
      "# Custom Queries\n",
      "Based on the provided context, the suppliers with a combination of poor quality metrics, high compliance issues, and good past performance scores are:\n",
      "\n",
      "1. Supplier 6\n",
      "2. Supplier 8\n",
      "3. Supplier 12\n",
      "4. Supplier 14\n",
      "5. Supplier 15\n",
      "6. Supplier 26\n",
      "7. Supplier 28\n",
      "8. Supplier 32\n",
      "9. Supplier 38\n",
      "10. Supplier 40\n",
      "\n",
      "\n",
      "The patterns between compliance issues and cost metrics in supplier contracts show that suppliers with higher risk levels and compliance issues tend to have higher cost metrics. Specifically, suppliers with non-compliance with standards and late delivery issues have higher unit costs and total costs compared to those with lower risk levels and fewer compliance issues. This suggests that addressing compliance issues could potentially lead to cost savings.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n## Risk-Based Queries\")\n",
    "\n",
    "question = \"Which suppliers have the most non-compliance issues, regardless of risk level?\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Compliance & Legal Queries:\")\n",
    "\n",
    "question = \"Identify suppliers where compliance monitoring is recommended.\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Cost and Financial Metrics:\")\n",
    "\n",
    "question = \"List suppliers that offer the best cost metrics but are classified as high risk.\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Contractual Terms and Recommendations:\")\n",
    "\n",
    "question = \"Which suppliers have penalty clauses for late delivery in their contracts, and what are the associated risks?\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Supplier Relationship Queries:\")\n",
    "\n",
    "question = \"What are the relationship metrics for suppliers with the best past performance scores?\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Opportunity and Innovation Queries:\")\n",
    "\n",
    "question = \"Identify suppliers with innovative solutions despite having poor quality metrics.\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n# Custom Queries\")\n",
    "\n",
    "question = \"Show me all suppliers with a combination of poor quality metrics, high compliance issues, and good past performance scores.\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "question = \"What are the patterns between compliance issues and cost metrics in supplier contracts?\"\n",
    "answer = rag(question)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f87d9c7-7030-4aa2-85c4-475f38ff510c",
   "metadata": {},
   "source": [
    "**Retrieval Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fbfa8de3-429b-470e-9ddb-ce3939eaec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9e0a5b5-ba46-425c-9bdd-f4743dd52fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_csv(r'/workspaces/Supply-Chain-Management/Data/ground-truth-retrieval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d80cba8-22c8-4707-987e-d3cd2d350788",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8370ef3f-0e1a-40a6-bac8-31a5d56cc9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5958c9aedb9542ea8660525dee4300ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.86384, 'mrr': 0.8502181587301586}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score += 1 / (rank + 1)\n",
    "                break  \n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e91d819-281f-428f-8f67-1209b44d8ea4",
   "metadata": {},
   "source": [
    "**Best Retrieval Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b749d-08f0-4bb7-9781-06be625dd350",
   "metadata": {},
   "source": [
    "Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ded4ca2a-4f0f-441d-859f-42f0894aded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_validation, df_test = train_test_split(df_question, test_size=0.5, random_state=42)\n",
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4514d762-dbfa-411e-af2c-dcdb34b9d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},  # Adjust filters if needed\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f31c9-45a1-4d33-91ce-a6983a765432",
   "metadata": {},
   "source": [
    "This function interacts with your search index. If no boost parameters are provided, it defaults to an empty dictionary. It returns the top 10 search results based on the query and the optional boost parameters. The boost_dict modifies the importance of specific fields during the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7a19140-e2eb-4f3f-9ebe-8c4575242a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_ranges = {\n",
    "    'supplier_name': (0.0, 3.0),\n",
    "    'supplier_type': (0.0, 3.0),\n",
    "    'risk_level': (0.0, 3.0),\n",
    "    'compliance_issues': (0.0, 3.0),\n",
    "    'key_terms': (0.0, 3.0),\n",
    "    'past_performance': (0.0, 3.0),\n",
    "    'negotiate_recommendation': (0.0, 3.0),\n",
    "    'supply_chain_disruption': (0.0, 3.0),\n",
    "    'quality_metrics': (0.0, 3.0),\n",
    "    'cost_metrics': (0.0, 3.0),\n",
    "}\n",
    "\n",
    "def objective(boost_params):\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q['question'], boost_params)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    return results['mrr']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f162a7b-ca03-4e66-8eb3-54f9e12c8b2b",
   "metadata": {},
   "source": [
    "This dictionary defines the range of values that each parameter can take during optimization. The values indicate how much weight or importance is assigned to each of these fields when retrieving results from the search index.\n",
    "\n",
    "The function evaluates the effectiveness of a particular set of boost parameters. It does so by calling minsearch_search with the boost parameters and calculating the Mean Reciprocal Rank (MRR) over the validation set (gt_val). The higher the MRR score, the better the ranking of relevant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b4c8acc-86ef-4936-bf6e-2a50224c0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def simple_optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf')  # Assuming we're minimizing. Use float('-inf') if maximizing.\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random parameters\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                current_params[param] = random.randint(min_val, max_val)\n",
    "            else:\n",
    "                current_params[param] = random.uniform(min_val, max_val)\n",
    "        \n",
    "        # Evaluate the objective function\n",
    "        current_score = objective_function(current_params)\n",
    "        \n",
    "        # Update best if current is better\n",
    "        if current_score > best_score:  # Change to > if maximizing\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "    \n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f54d253-420a-4f52-a92c-f2e55cb0617a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b34fc0e0fb4b928f87b4fd4d66ded0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6512ce2007446abfa7cf9b6ccc9ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2cc58a972047488182e1019dc09018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bcc3232f6f429aaaa3c431d6af022c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0e89caae774746a920af19d5231749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f84e5b282647f0993bdc2ce76c2d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc045d648bac4f588c5ea56dba69fbf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a600f83b674ab18284c4259dc3c75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73961fda70f490190433b826b63d605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d455c5c0c09c4c77a37190acee6e3879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4530d0fc081743ee819636be77f195b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542f4fda831f427297d8c4ea7e5d7123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6504adf64d4849a19447df5f44f577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ba1939e2be40b38a57cfec0bd112d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0901881ca0642279ac1231c633aeabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f21f88bc0b94632a463eb5ebe29f920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204011e8d74346db9ecee240d8b9622c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06bbaf3acd94b5f8bcdbb597b7b7941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88834b3cdb7a44e683bf33e57736066a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3cb357d6564b8ea9601169fff9af59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Boost Parameters: {'supplier_name': 2.8691396940069374, 'supplier_type': 1.8940336800638193, 'risk_level': 0.923442405280464, 'compliance_issues': 2.407565036605866, 'key_terms': 0.3208613898026407, 'past_performance': 1.4030636901968452, 'negotiate_recommendation': 0.7292841547630614, 'supply_chain_disruption': 1.650281040936573, 'quality_metrics': 0.15471113546029314, 'cost_metrics': 1.2247811572567455}\n",
      "Best MRR Score: 0.9346627936507936\n"
     ]
    }
   ],
   "source": [
    "best_params, best_score = simple_optimize(param_ranges, objective, n_iterations=20)\n",
    "\n",
    "print(\"Best Boost Parameters:\", best_params)\n",
    "print(\"Best MRR Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5858c06a-f10d-4610-a7b8-77c5ff8b0055",
   "metadata": {},
   "source": [
    "This is the optimized search function using the best boost parameters obtained from the optimization step. These parameters are applied to the search function, and it is evaluated using the full ground truth dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e170b464-c6ef-4cbc-b9d0-8931253171aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c031ea13239490f9ece2a0db3175994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.93696, 'mrr': 0.9342981269841271}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minsearch_improved(query):\n",
    "    boost = {\n",
    "        'supplier_name': best_params['supplier_name'],\n",
    "        'supplier_type': best_params['supplier_type'],\n",
    "        'risk_level': best_params['risk_level'],\n",
    "        'compliance_issues': best_params['compliance_issues'],\n",
    "        'key_terms': best_params['key_terms'],\n",
    "        'past_performance': best_params['past_performance'],\n",
    "        'negotiate_recommendation': best_params['negotiate_recommendation'],\n",
    "        'supply_chain_disruption': best_params['supply_chain_disruption'],\n",
    "        'quality_metrics': best_params['quality_metrics'],\n",
    "        'cost_metrics': best_params['cost_metrics']\n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "evaluate(ground_truth, lambda q: minsearch_improved(q['question']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc75592-fba1-468c-a768-81fc33645165",
   "metadata": {},
   "source": [
    "Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f003abce-d718-40d0-bc4e-a1c5e03fee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2d4a4130-516f-41a7-a7ae-459b911531aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24101a802c75484b951ef76a4df55dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Hit Rate: 0.97296\n",
      "TF-IDF MRR: 0.9553497460317472\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Ensure the text is a string\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        # Additional preprocessing steps like removing punctuation can be added here\n",
    "        return text\n",
    "    return ''\n",
    "\n",
    "# Apply preprocessing\n",
    "df_question['processed_question'] = df_question['question'].apply(preprocess_text)\n",
    "\n",
    "# Prepare TF-IDF Vectorizer with custom settings\n",
    "corpus = df_question['processed_question'].tolist()\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),  # Bi-grams\n",
    "    stop_words='english',  # Use English stop words\n",
    "    sublinear_tf=True  # Sublinear term frequency scaling\n",
    ")\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "def tfidf_search(query, num_results=10):\n",
    "    query_processed = preprocess_text(query)\n",
    "    query_vec = vectorizer.transform([query_processed])\n",
    "    similarities = cosine_similarity(query_vec, X).flatten()\n",
    "    top_indices = np.argsort(similarities)[::-1][:num_results]\n",
    "    return df_question.iloc[top_indices].to_dict(orient='records')\n",
    "\n",
    "def evaluate_tfidf(ground_truth):\n",
    "    relevance_total = []\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = tfidf_search(q['question'])\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n",
    "\n",
    "# Evaluate TF-IDF retrieval approach\n",
    "tfidf_results = evaluate_tfidf(ground_truth)\n",
    "print('TF-IDF Hit Rate:', tfidf_results['hit_rate'])\n",
    "print('TF-IDF MRR:', tfidf_results['mrr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f8e07b5-7794-4176-a8b9-98e928cf7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best one among the the two \n",
    "def compare_methods(ground_truth, best_params):\n",
    "    # Evaluate TF-IDF\n",
    "    tfidf_results = evaluate_tfidf(ground_truth)\n",
    "    \n",
    "    # Evaluate Minsearch\n",
    "    minsearch_results = evaluate(ground_truth, best_params)\n",
    "\n",
    "    print(\"TF-IDF Results:\")\n",
    "    print('Hit Rate:', tfidf_results['hit_rate'])\n",
    "    print('MRR:', tfidf_results['mrr'])\n",
    "\n",
    "    print(\"Minsearch Results:\")\n",
    "    print('Hit Rate:', minsearch_results['hit_rate'])\n",
    "    print('MRR:', minsearch_results['mrr'])\n",
    "\n",
    "    if tfidf_results['mrr'] > minsearch_results['mrr']:\n",
    "        return 'TF-IDF', tfidf_results\n",
    "    else:\n",
    "        return 'Minsearch', minsearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f3c6ed1a-a96e-4ac0-a996-2512b7af711e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97bb9583d23d489bb4a914543e443210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45fba1bf5464a038b19ddb51068698e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Results:\n",
      "Hit Rate: 0.97296\n",
      "MRR: 0.9553497460317472\n",
      "Minsearch Results:\n",
      "Hit Rate: 0.93696\n",
      "MRR: 0.9342981269841271\n"
     ]
    }
   ],
   "source": [
    "results = compare_methods(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b747c380-28c5-40e1-8dd7-e568dad15b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TF-IDF', {'hit_rate': 0.97296, 'mrr': 0.9553497460317472})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c1745-3320-4ed8-907e-1c872b95caab",
   "metadata": {},
   "source": [
    "**RAG evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a179961a-83ad-4b9e-a1dd-314b1a9eddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f17517b-959d-48ce-a200-fd684f40ce0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8ab18b4-67c5-4276-95df-6deb2d01e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9b232bd-6cb7-4092-94a4-60048a19bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = record['question']\n",
    "answer_llm = rag(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "72d688b4-1246-4e1b-8200-8015b276b68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supplier 1 has a high risk level and has had compliance issues with non-compliance with standards.\n"
     ]
    }
   ],
   "source": [
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "49608ac4-2542-4c28-849c-625a993dabc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: What is the risk level of Supplier 1 and what compliance issues have they had?\n",
      "Generated Answer: Supplier 1 has a high risk level and has had compliance issues with non-compliance with standards.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39e98d91-4ab6-4f56-a818-475df561d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f153feb1-0068-40ba-8908-007a8c1a0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_question.sample(n=1250, random_state=1)\n",
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "194f57e5-2897-4f60-9598-70cfaebcba38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9039d2c5149a4f66bd2d0faec84e4b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m answer_llm \u001b[38;5;241m=\u001b[39m rag(question) \n\u001b[1;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt2_template\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m      8\u001b[0m     question\u001b[38;5;241m=\u001b[39mquestion,\n\u001b[1;32m      9\u001b[0m     answer_llm\u001b[38;5;241m=\u001b[39manswer_llm\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(evaluation)\n\u001b[1;32m     15\u001b[0m evaluations\u001b[38;5;241m.\u001b[39mappend((record, answer_llm, evaluation))\n",
      "Cell \u001b[0;32mIn[55], line 41\u001b[0m, in \u001b[0;36mllm\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllm\u001b[39m(prompt, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLlama3-groq-70b-8192-tool-use-preview\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Assuming client is the Groq API client instance\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/groq/resources/chat/completions.py:287\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    176\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/groq/_base_client.py:1244\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1232\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1239\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1240\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1241\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1242\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1243\u001b[0m     )\n\u001b[0;32m-> 1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/groq/_base_client.py:936\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    929\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/groq/_base_client.py:1024\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1023\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/groq/_base_client.py:1073\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/groq/_base_client.py:1039\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1038\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1039\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1042\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1043\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[1;32m   1048\u001b[0m )\n",
      "\u001b[0;31mInternalServerError\u001b[0m: Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}"
     ]
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question) \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262948ad-86dc-4b37-9e54-3b5e34a113c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4531ea5-e9d6-4433-950b-8f9140b81a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a129b86-5441-47c3-9e6d-b9c6cf9b71d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv(r'/workspaces/Supply-Chain-Management/Data/Evaluation/rag-eval-gpt-4o-mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b454e-96c2-4d07-930b-6ac386c4fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eval[df_eval.relevance == 'NON_RELEVANT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8419cf-38e3-4f09-a102-c3cfef7eaae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluations_gpt4o = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question, model='gpt-4o') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    \n",
    "    evaluations_gpt4o.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520669d-359b-4062-aabf-a1b574f51f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eval = pd.DataFrame(evaluations_gpt4o, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe34b5-ed2a-4700-9526-f85743beec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv(r'/workspaces/Supply-Chain-Management/Data/Evaluation/rag-eval-gpt-4o.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44545a79-6fd1-4d5f-9b81-2dd29726829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Define the LLaMA model and tokenizer\n",
    "model_name = \"huggingface/llama-3b\"  # Replace with the actual model name\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Function to get the LLaMA model's response\n",
    "def llama_model(query):\n",
    "    inputs = tokenizer(query, return_tensors='pt')\n",
    "    outputs = model.generate(inputs['input_ids'], max_length=100)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer\n",
    "\n",
    "# Function to calculate perplexity\n",
    "def calculate_perplexity(query, answer):\n",
    "    inputs = tokenizer(query, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    loss = outputs.loss\n",
    "    perplexity = torch.exp(loss)\n",
    "    return perplexity.item()\n",
    "\n",
    "# Evaluation template\n",
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "# Sample data for evaluation\n",
    "df_sample = df_question.sample(n=1250, random_state=1)\n",
    "sample = df_sample.to_dict(orient='records')\n",
    "\n",
    "# Perform manual evaluation\n",
    "evaluations_llama = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = llama_model(question)\n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    perplexity = calculate_perplexity(question, answer_llm)\n",
    "\n",
    "    evaluations_llama.append((record, answer_llm, evaluation, perplexity))\n",
    "\n",
    "# Create DataFrame for evaluations\n",
    "df_eval = pd.DataFrame(evaluations_llama, columns=['record', 'answer', 'evaluation', 'perplexity'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']\n",
    "\n",
    "# Analyze results\n",
    "relevance_distribution = df_eval.relevance.value_counts(normalize=True)\n",
    "non_relevant_responses = df_eval[df_eval.relevance == 'NON_RELEVANT']\n",
    "\n",
    "# Print relevance distribution\n",
    "print(relevance_distribution)\n",
    "\n",
    "# Display non-relevant responses\n",
    "print(non_relevant_responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6596127b-adf5-4ee8-8fcb-9e2e91818f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.7-py3-none-any.whl (417 kB)\n",
      "Downloading regex-2024.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (797 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m\u001b[0m \u001b[32m797.0/797.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (434 kB)\n",
      "Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.24.7 regex-2024.9.11 safetensors-0.4.5 tokenizers-0.19.1 transformers-4.44.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
