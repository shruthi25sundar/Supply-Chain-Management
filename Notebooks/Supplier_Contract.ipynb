{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9b16e8-270c-4400-a05b-8ff32a69a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d218b60-eebb-4321-90a2-44a7301f88f7",
   "metadata": {},
   "source": [
    "**INGESTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b827ed-d3b7-47fc-ad29-b48a15dcba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"/workspaces/Supply-Chain-Management/Data/supplier_contracts_dataset.csv\")\n",
    "df = df.replace({np.nan: None})\n",
    "# Rename columns to remove spaces\n",
    "# df.columns = [col.replace(' ', '_') for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb664984-a7ef-4200-b6b5-3e4038f6141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = df.columns.str.lower()\n",
    "# df.to_csv(r\"/workspaces/Supply-Chain-Management/Data/supplier_contracts_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4aa868-e50f-42a6-83c1-edad05481382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['supplier_id', 'supplier_name', 'supplier_type', 'risk_level',\n",
       "       'compliance_issues', 'key_terms', 'past_performance',\n",
       "       'negotiate_recommendation', 'supply_chain_disruption',\n",
       "       'quality_metrics', 'cost_metrics'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0882f38e-bfb0-4a6d-8e86-b800e487995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.rename(columns={'supplier_id':'id'})\n",
    "# # Convert only the relevant text-based fields to string\n",
    "text_fields = ['supplier_name', 'supplier_type', 'risk_level',\n",
    "       'compliance_issues', 'key_terms', 'past_performance',\n",
    "       'negotiate_recommendation', 'supply_chain_disruption',\n",
    "       'quality_metrics', 'cost_metrics']\n",
    "\n",
    "# Ensure the specified text fields are strings\n",
    "for field in text_fields:\n",
    "    df[field] = df[field].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72f92f7-1a8a-4269-8b50-73344ed859c7",
   "metadata": {},
   "source": [
    "**Indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6183ad8-eecb-4b0c-89d5-88e50fcd868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = df.columns.str.lower()\n",
    "# df.to_csv(r\"/workspaces/Supply-Chain-Management/Data/supplier_contracts_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a10368-dd4e-4f83-b5c1-0188e0a964d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300178f7-1cb6-46de-8d96-5375400164ea",
   "metadata": {},
   "source": [
    "Get top 10 list of high risk level contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43b9cd5b-c404-476c-9390-2bf2f2dc600f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'S0430', 'supplier_name': 'Supplier 430', 'supplier_type': 'Service Provider', 'risk_level': 'High', 'compliance_issues': 'None', 'key_terms': '45-day payment, 10-day delivery', 'past_performance': 'Poor', 'negotiate_recommendation': 'Adjust delivery schedules, Include compliance monitoring, Include penalty clauses for late delivery', 'supply_chain_disruption': 'Yes', 'quality_metrics': '4.22% defect rate, Meets standards', 'cost_metrics': '$69.97/unit, $6563.98 total cost'}\n",
      "{'id': 'S1311', 'supplier_name': 'Supplier 1311', 'supplier_type': 'Manufacturer', 'risk_level': 'High', 'compliance_issues': 'Non-Compliance with Standards', 'key_terms': '45-day payment, 10-day delivery', 'past_performance': 'Poor', 'negotiate_recommendation': 'Adjust delivery schedules, Include compliance monitoring, Include penalty clauses for late delivery', 'supply_chain_disruption': 'Yes', 'quality_metrics': '4.61% defect rate, Meets standards', 'cost_metrics': '$52.85/unit, $6165.72 total cost'}\n",
      "{'id': 'S0801', 'supplier_name': 'Supplier 801', 'supplier_type': 'Retailer', 'risk_level': 'High', 'compliance_issues': 'Late Delivery', 'key_terms': '60-day payment, 7-day delivery', 'past_performance': 'Good', 'negotiate_recommendation': 'Seek alternative suppliers, Include penalty clauses for late delivery, Adjust delivery schedules', 'supply_chain_disruption': 'No', 'quality_metrics': '2.1% defect rate, Meets standards', 'cost_metrics': '$55.48/unit, $6206.18 total cost'}\n",
      "{'id': 'S1855', 'supplier_name': 'Supplier 1855', 'supplier_type': 'Retailer', 'risk_level': 'High', 'compliance_issues': 'Late Delivery', 'key_terms': '30-day payment, 5-day delivery', 'past_performance': 'Fair', 'negotiate_recommendation': 'Seek alternative suppliers, Include penalty clauses for late delivery, Include compliance monitoring', 'supply_chain_disruption': 'No', 'quality_metrics': '3.79% defect rate, Meets standards', 'cost_metrics': '$57.42/unit, $6714.71 total cost'}\n",
      "{'id': 'S0441', 'supplier_name': 'Supplier 441', 'supplier_type': 'Manufacturer', 'risk_level': 'High', 'compliance_issues': 'None', 'key_terms': '45-day payment, 10-day delivery', 'past_performance': 'Excellent', 'negotiate_recommendation': 'Adjust delivery schedules, Seek alternative suppliers, Include penalty clauses for late delivery', 'supply_chain_disruption': 'No', 'quality_metrics': '1.89% defect rate, Meets standards', 'cost_metrics': '$56.72/unit, $5523.25 total cost'}\n",
      "{'id': 'S1844', 'supplier_name': 'Supplier 1844', 'supplier_type': 'Distributor', 'risk_level': 'High', 'compliance_issues': 'None', 'key_terms': '45-day payment, 10-day delivery', 'past_performance': 'Good', 'negotiate_recommendation': 'Include compliance monitoring, Include penalty clauses for late delivery, Seek alternative suppliers', 'supply_chain_disruption': 'Yes', 'quality_metrics': '3.77% defect rate, Meets standards', 'cost_metrics': '$64.17/unit, $6985.11 total cost'}\n",
      "{'id': 'S1842', 'supplier_name': 'Supplier 1842', 'supplier_type': 'Distributor', 'risk_level': 'High', 'compliance_issues': 'None', 'key_terms': '60-day payment, 7-day delivery', 'past_performance': 'Fair', 'negotiate_recommendation': 'Include penalty clauses for late delivery, Adjust delivery schedules, Seek alternative suppliers', 'supply_chain_disruption': 'Yes', 'quality_metrics': '2.86% defect rate, Meets standards', 'cost_metrics': '$56.6/unit, $5890.59 total cost'}\n",
      "{'id': 'S0438', 'supplier_name': 'Supplier 438', 'supplier_type': 'Distributor', 'risk_level': 'High', 'compliance_issues': 'Non-Compliance with Standards', 'key_terms': '30-day payment, 5-day delivery', 'past_performance': 'Good', 'negotiate_recommendation': 'Seek alternative suppliers, Include compliance monitoring, Adjust delivery schedules', 'supply_chain_disruption': 'Yes', 'quality_metrics': '1.61% defect rate, Meets standards', 'cost_metrics': '$54.41/unit, $5361.45 total cost'}\n",
      "{'id': 'S1840', 'supplier_name': 'Supplier 1840', 'supplier_type': 'Manufacturer', 'risk_level': 'High', 'compliance_issues': 'Non-Compliance with Standards', 'key_terms': '60-day payment, 7-day delivery', 'past_performance': 'Fair', 'negotiate_recommendation': 'Include compliance monitoring, Include penalty clauses for late delivery, Seek alternative suppliers', 'supply_chain_disruption': 'No', 'quality_metrics': '4.95% defect rate, Meets standards', 'cost_metrics': '$60.63/unit, $5250.09 total cost'}\n",
      "{'id': 'S0495', 'supplier_name': 'Supplier 495', 'supplier_type': 'Service Provider', 'risk_level': 'High', 'compliance_issues': 'Late Delivery', 'key_terms': '45-day payment, 10-day delivery', 'past_performance': 'Poor', 'negotiate_recommendation': 'Include penalty clauses for late delivery, Include compliance monitoring, Seek alternative suppliers', 'supply_chain_disruption': 'No', 'quality_metrics': '1.67% defect rate, Meets standards', 'cost_metrics': '$69.61/unit, $6142.64 total cost'}\n"
     ]
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "# Create an index\n",
    "index = minsearch.Index(\n",
    "    text_fields=text_fields,\n",
    "    keyword_fields=[]\n",
    ")\n",
    "\n",
    "# Fit the index with the documents\n",
    "index.fit(documents)\n",
    "\n",
    "# Example search query\n",
    "query = \"high risk level\"\n",
    "results = index.search(query, num_results=10)\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c74c41-7f4e-4e5b-b043-cb561d3545ff",
   "metadata": {},
   "source": [
    "*Get the Contract types that has high risk and their count*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884b4c83-5084-4261-8294-d96ccc7d5f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each supplier type with high risk level:\n",
      "Manufacturer: 201\n",
      "Service Provider: 219\n",
      "Retailer: 197\n",
      "Distributor: 198\n"
     ]
    }
   ],
   "source": [
    "import minsearch\n",
    "from collections import Counter\n",
    "# Create an index\n",
    "index = minsearch.Index(\n",
    "    text_fields=text_fields,\n",
    "    keyword_fields=['risk_level']\n",
    ")\n",
    "\n",
    "# Fit the index with the documents\n",
    "index.fit(documents)\n",
    "\n",
    "# Perform the search for high-risk level contracts\n",
    "filter_dict = {'risk_level': 'High'}\n",
    "results = index.search(query='high risk level', filter_dict=filter_dict, num_results=len(documents))\n",
    "\n",
    "# Extract and print contract types with high risk level\n",
    "high_risk_contract_types = [result['supplier_type'] for result in results]\n",
    "\n",
    "# Count the occurrences of each contract type\n",
    "contract_type_counts = Counter(high_risk_contract_types)\n",
    "\n",
    "# Print the count of each contract type\n",
    "print(\"Count of each supplier type with high risk level:\")\n",
    "for contract_type, count in contract_type_counts.items():\n",
    "    print(f\"{contract_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cba7a3d-375a-446f-99f1-784b93b04861",
   "metadata": {},
   "source": [
    "**RAG flow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4215677c-21b6-421a-a293-51059466e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55dcc07c-a334-4093-a931-a8d36579dc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supplier 6: Manufacturer\n",
      "- Quality Metrics: 3.43% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: Yes\n",
      "- Negotiation Recommendations: Seek alternative suppliers, Include penalty clauses for late delivery, Adjust delivery schedules\n",
      "\n",
      "Supplier 8: Retailer\n",
      "- Quality Metrics: 4.38% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: Yes\n",
      "- Negotiation Recommendations: Include penalty clauses for late delivery, Seek alternative suppliers, Adjust delivery schedules\n",
      "\n",
      "Supplier 12: Distributor\n",
      "- Quality Metrics: 3.84% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: Yes\n",
      "- Negotiation Recommendations: Include compliance monitoring, Include penalty clauses for late delivery, Seek alternative suppliers\n",
      "\n",
      "Supplier 14: Service Provider\n",
      "- Quality Metrics: 2.45% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: Yes\n",
      "- Negotiation Recommendations: Seek alternative suppliers, Adjust delivery schedules, Include compliance monitoring\n",
      "\n",
      "Supplier 15: Distributor\n",
      "- Quality Metrics: 1.81% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: No\n",
      "- Negotiation Recommendations: Seek alternative suppliers, Adjust delivery schedules, Include penalty clauses for late delivery\n",
      "\n",
      "Supplier 26: Distributor\n",
      "- Quality Metrics: 4.27% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: Yes\n",
      "- Negotiation Recommendations: Include compliance monitoring, Seek alternative suppliers, Adjust delivery schedules\n",
      "\n",
      "Supplier 28: Retailer\n",
      "- Quality Metrics: 3.01% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: No\n",
      "- Negotiation Recommendations: Seek alternative suppliers, Include compliance monitoring, Include penalty clauses for late delivery\n",
      "\n",
      "Supplier 32: Retailer\n",
      "- Quality Metrics: 1.48% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: No\n",
      "- Negotiation Recommendations: Include penalty clauses for late delivery, Seek alternative suppliers, Adjust delivery schedules\n",
      "\n",
      "Supplier 38: Retailer\n",
      "- Quality Metrics: 4.68% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: Yes\n",
      "- Negotiation Recommendations: Seek alternative suppliers, Adjust delivery schedules, Include penalty clauses for late delivery\n",
      "\n",
      "Supplier 40: Retailer\n",
      "- Quality Metrics: 1.76% defect rate, Meets standards\n",
      "- Supply Chain Disruptions: No\n",
      "- Negotiation Recommendations: Include penalty clauses for late delivery, Include compliance monitoring, Adjust delivery schedules\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to perform the search on supplier contracts based on query\n",
    "\n",
    "def search(query, filter_dict=None, max_results=10):\n",
    "    # Filter the DataFrame based on risk level (if provided)\n",
    "    if filter_dict:\n",
    "        filtered_df = df[df['risk_level'] == filter_dict.get('risk_level', '')]\n",
    "    else:\n",
    "        filtered_df = df\n",
    "    # Convert the filtered data to a list of dictionaries and limit the number of results\n",
    "    results = filtered_df.to_dict(orient='records')[:max_results]\n",
    "    return results\n",
    "\n",
    "# Function to build a clearer prompt for Groq API\n",
    "def build_clear_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context += (\n",
    "            f\"- **Supplier_Type**: {doc['supplier_type']}\\n\"\n",
    "            f\"  **Supplier_Name**: {doc['supplier_name']}\\n\"\n",
    "            f\"  **Risk_Level**: {doc['risk_level']}\\n\"\n",
    "            f\"  **Compliance_Issues**: {doc['compliance_issues']}\\n\"\n",
    "            f\"  **Key_Terms**: {doc['key_terms']}\\n\"\n",
    "            f\"  **Negotiate_Recommendation**: {doc['negotiate_recommendation']}\\n\"\n",
    "            f\"  **Quality_Metrics**: {doc['quality_metrics']}\\n\"\n",
    "            f\"  **Past_Performance**: {doc['past_performance']}\\n\"\n",
    "            f\"  **Supply_Chain_Disruption**: {doc['supply_chain_disruption']}\\n\"\n",
    "            f\"  **Cost_Metrics**: {doc['cost_metrics']}\\n\\n\"\n",
    "        )\n",
    "    \n",
    "    prompt = (\n",
    "        f\"QUESTION: {query}\\n\\n\"\n",
    "        f\"CONTEXT:\\n{context}\"\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Function to call the LLM (Groq API)\n",
    "def llm(prompt, model='Llama3-groq-70b-8192-tool-use-preview'):\n",
    "    # Assuming client is the Groq API client instance\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Function to perform the full RAG (Retrieve and Generate) process\n",
    "def rag(query, model='Llama3-groq-70b-8192-tool-use-preview'):\n",
    "    # Search for high-risk contracts (you can modify filter_dict based on needs)\n",
    "    search_results = search(query, filter_dict={'risk_level': 'High'})\n",
    "    \n",
    "    # Build the prompt using the search results\n",
    "    prompt = build_clear_prompt(query, search_results)\n",
    "    \n",
    "    # Get the LLM response based on the prompt\n",
    "    answer = llm(prompt, model=model)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "question = \"Give supplier types, quality metrics, supply chain disruptions, and their negotiation recommendations for high-risk contracts\"\n",
    "answer = rag(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da304f86-6d92-490a-8769-2aa75162d14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Risk-Based Queries\n",
      "Supplier 6, Supplier 8, Supplier 12, Supplier 14, Supplier 15, Supplier 26, Supplier 28, Supplier 32, Supplier 38, and Supplier 40 all have non-compliance issues regardless of risk level.\n",
      "\n",
      "## Compliance & Legal Queries:\n",
      "Based on the provided data, the suppliers where compliance monitoring is recommended are:\n",
      "\n",
      "1. Supplier 12\n",
      "2. Supplier 40\n",
      "\n",
      "## Cost and Financial Metrics:\n",
      "Supplier 6, Supplier 8, Supplier 12, Supplier 14, Supplier 15, Supplier 26, Supplier 28, Supplier 32, Supplier 38, Supplier 40\n",
      "\n",
      "## Contractual Terms and Recommendations:\n",
      "Based on the provided data, the suppliers with penalty clauses for late delivery in their contracts are:\n",
      "\n",
      "1. Supplier 6\n",
      "2. Supplier 8\n",
      "3. Supplier 12\n",
      "4. Supplier 14\n",
      "5. Supplier 15\n",
      "6. Supplier 26\n",
      "7. Supplier 28\n",
      "8. Supplier 32\n",
      "9. Supplier 38\n",
      "10. Supplier 40\n",
      "\n",
      "The associated risks with these suppliers include:\n",
      "\n",
      "1. Supplier 6: High risk due to non-compliance with standards and supply chain disruption.\n",
      "2. Supplier 8: High risk due to non-compliance with standards and supply chain disruption.\n",
      "3. Supplier 12: High risk due to substandard quality and supply chain disruption.\n",
      "4. Supplier 14: High risk due to non-compliance with standards and supply chain disruption.\n",
      "5. Supplier 15: High risk due to non-compliance with standards and no supply chain disruption.\n",
      "6. Supplier 26: High risk due to late delivery and supply chain disruption.\n",
      "7. Supplier 28: High risk due to late delivery and no supply chain disruption.\n",
      "8. Supplier 32: High risk due to non-compliance with standards and no supply chain disruption.\n",
      "9. Supplier 38: High risk due to late delivery and supply chain disruption.\n",
      "10. Supplier 40: High risk due to non-compliance with standards and no supply chain disruption.\n",
      "\n",
      "## Supplier Relationship Queries:\n",
      "The relationship metrics for suppliers with the best past performance scores are as follows:\n",
      "\n",
      "1. Supplier 14 (Service Provider): Excellent past performance, 2.45% defect rate, and $69.82/unit cost.\n",
      "2. Supplier 26 (Distributor): Excellent past performance, 4.27% defect rate, and $65.79/unit cost.\n",
      "3. Supplier 32 (Retailer): Excellent past performance, 1.48% defect rate, and $56.9/unit cost.\n",
      "4. Supplier 38 (Retailer): Excellent past performance, 4.68% defect rate, and $57.93/unit cost.\n",
      "5. Supplier 40 (Retailer): Excellent past performance, 1.76% defect rate, and $66.89/unit cost.\n",
      "\n",
      "## Opportunity and Innovation Queries:\n",
      "Supplier 6, Supplier 8, Supplier 12, Supplier 14, Supplier 15, Supplier 26, Supplier 28, Supplier 32, Supplier 38, and Supplier 40 are suppliers with innovative solutions despite having poor quality metrics.\n",
      "\n",
      "# Custom Queries\n",
      "Based on the provided information, the suppliers with a combination of poor quality metrics, high compliance issues, and good past performance scores are:\n",
      "\n",
      "1. Supplier 6\n",
      "2. Supplier 8\n",
      "3. Supplier 12\n",
      "4. Supplier 14\n",
      "5. Supplier 26\n",
      "6. Supplier 28\n",
      "7. Supplier 32\n",
      "8. Supplier 38\n",
      "9. Supplier 40\n",
      "\n",
      "\n",
      "The patterns between compliance issues and cost metrics in supplier contracts can be observed in the following ways:\n",
      "\n",
      "1. **High Risk Level and Compliance Issues**: All suppliers with a high risk level have compliance issues, either with non-compliance with standards, late delivery, or substandard quality. This indicates that suppliers with higher risk levels are more likely to have compliance issues.\n",
      "\n",
      "2. **Compliance Issues and Cost Metrics**: Suppliers with compliance issues generally have higher cost metrics. For example, Supplier 6 has a high defect rate and higher cost metrics compared to Supplier 32, which has a lower defect rate and lower cost metrics. This suggests that compliance issues may lead to higher costs.\n",
      "\n",
      "3. **Risk Level and Cost Metrics**: Suppliers with a high risk level tend to have higher cost metrics. For instance, Supplier 14 has a high risk level and higher cost metrics compared to Supplier 32, which has a lower risk level and lower cost metrics. This indicates that higher risk levels may result in higher costs.\n",
      "\n",
      "4. **Supplier Type and Cost Metrics**: Retailers tend to have higher cost metrics compared to manufacturers and distributors. This could be due to the nature of their business, as retailers often have higher overhead costs.\n",
      "\n",
      "5. **Negotiation Recommendations**: The negotiation recommendations often include seeking alternative suppliers, adjusting delivery schedules, and including penalty clauses for late delivery. These recommendations are more common for suppliers with compliance issues and higher cost metrics, suggesting that addressing these issues could potentially lower costs.\n",
      "\n",
      "6. **Supply Chain Disruption and Cost Metrics**: Suppliers experiencing supply chain disruptions tend to have higher cost metrics. For example, Supplier 14 has a high risk level, compliance issues, and higher cost metrics, while Supplier 32 has a lower risk level, no compliance issues, and lower cost metrics. This indicates that supply chain disruptions can lead to higher costs.\n",
      "\n",
      "7. **Quality Metrics and Cost Metrics**: Suppliers with higher defect rates tend to have higher cost metrics. For instance, Supplier 6 has a higher defect rate and higher cost metrics compared to Supplier 32, which has a lower defect rate and lower cost metrics. This suggests that improving quality metrics could potentially lower costs.\n",
      "\n",
      "8. **Past Performance and Cost Metrics**: Suppliers with excellent past performance tend to have lower cost metrics. For example, Supplier 32 has excellent past performance and lower cost metrics, while Supplier 6 has good past performance and higher cost metrics. This indicates that suppliers with better past performance may offer more competitive pricing.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n## Risk-Based Queries\")\n",
    "\n",
    "question = \"Which suppliers have the most non-compliance issues, regardless of risk level?\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Compliance & Legal Queries:\")\n",
    "\n",
    "question = \"Identify suppliers where compliance monitoring is recommended.\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Cost and Financial Metrics:\")\n",
    "\n",
    "question = \"List suppliers that offer the best cost metrics but are classified as high risk.\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Contractual Terms and Recommendations:\")\n",
    "\n",
    "question = \"Which suppliers have penalty clauses for late delivery in their contracts, and what are the associated risks?\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Supplier Relationship Queries:\")\n",
    "\n",
    "question = \"What are the relationship metrics for suppliers with the best past performance scores?\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Opportunity and Innovation Queries:\")\n",
    "\n",
    "question = \"Identify suppliers with innovative solutions despite having poor quality metrics.\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n# Custom Queries\")\n",
    "\n",
    "question = \"Show me all suppliers with a combination of poor quality metrics, high compliance issues, and good past performance scores.\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "question = \"What are the patterns between compliance issues and cost metrics in supplier contracts?\"\n",
    "answer = rag(question)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f87d9c7-7030-4aa2-85c4-475f38ff510c",
   "metadata": {},
   "source": [
    "**Retrieval Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbfa8de3-429b-470e-9ddb-ce3939eaec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9e0a5b5-ba46-425c-9bdd-f4743dd52fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_csv(r'/workspaces/Supply-Chain-Management/Data/ground-truth-retrieval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d80cba8-22c8-4707-987e-d3cd2d350788",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8370ef3f-0e1a-40a6-bac8-31a5d56cc9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9275840872d4934a74fd2df7cb0712b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.86392, 'mrr': 0.850265492063492}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score += 1 / (rank + 1)\n",
    "                break  \n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e91d819-281f-428f-8f67-1209b44d8ea4",
   "metadata": {},
   "source": [
    "**Best Retrieval Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b749d-08f0-4bb7-9781-06be625dd350",
   "metadata": {},
   "source": [
    "Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ded4ca2a-4f0f-441d-859f-42f0894aded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_validation, df_test = train_test_split(df_question, test_size=0.5, random_state=42)\n",
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4514d762-dbfa-411e-af2c-dcdb34b9d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},  # Adjust filters if needed\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f31c9-45a1-4d33-91ce-a6983a765432",
   "metadata": {},
   "source": [
    "This function interacts with your search index. If no boost parameters are provided, it defaults to an empty dictionary. It returns the top 10 search results based on the query and the optional boost parameters. The boost_dict modifies the importance of specific fields during the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7a19140-e2eb-4f3f-9ebe-8c4575242a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_ranges = {\n",
    "    'supplier_name': (0.0, 3.0),\n",
    "    'supplier_type': (0.0, 3.0),\n",
    "    'risk_level': (0.0, 3.0),\n",
    "    'compliance_issues': (0.0, 3.0),\n",
    "    'key_terms': (0.0, 3.0),\n",
    "    'past_performance': (0.0, 3.0),\n",
    "    'negotiate_recommendation': (0.0, 3.0),\n",
    "    'supply_chain_disruption': (0.0, 3.0),\n",
    "    'quality_metrics': (0.0, 3.0),\n",
    "    'cost_metrics': (0.0, 3.0),\n",
    "}\n",
    "\n",
    "def objective(boost_params):\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q['question'], boost_params)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    return results['mrr']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f162a7b-ca03-4e66-8eb3-54f9e12c8b2b",
   "metadata": {},
   "source": [
    "This dictionary defines the range of values that each parameter can take during optimization. The values indicate how much weight or importance is assigned to each of these fields when retrieving results from the search index.\n",
    "\n",
    "The function evaluates the effectiveness of a particular set of boost parameters. It does so by calling minsearch_search with the boost parameters and calculating the Mean Reciprocal Rank (MRR) over the validation set (gt_val). The higher the MRR score, the better the ranking of relevant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b4c8acc-86ef-4936-bf6e-2a50224c0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def simple_optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf')  # Assuming we're minimizing. Use float('-inf') if maximizing.\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random parameters\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                current_params[param] = random.randint(min_val, max_val)\n",
    "            else:\n",
    "                current_params[param] = random.uniform(min_val, max_val)\n",
    "        \n",
    "        # Evaluate the objective function\n",
    "        current_score = objective_function(current_params)\n",
    "        \n",
    "        # Update best if current is better\n",
    "        if current_score > best_score:  # Change to > if maximizing\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "    \n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f54d253-420a-4f52-a92c-f2e55cb0617a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17336e8298444f59e789f7c169ddead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b583b3703a44359fafc5fe486fec14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d3836b112d429892b81c2bb0d4e7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eae89131c6747e3a56d574a2d6a70c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdfaacc42714c55921f0c21f5db5265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a164d1a389d4592a9cb41e1edad4d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5f709c1aee44349a504777e7da73dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3c6f4445194059bef070391d6a53f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd37c7ab3bb84a9795637dfc9afad626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4676ba4a2f45729caa9d882efc8b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4239b5447074483f9c5689bff09b533c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc485c881e04bd2887f43d0df58714a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0779aa70f6b04948972c068368fcad26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39f49bd89a947a791ffad2342073134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49341d0287684e229ae787262beef011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a41a6538f348189cb3b0293ee63a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb897228d384a04ba852bea54e4049f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dc18f8e52c4d4ba9cd14edf73a3580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d76617e23b044409a14a81afac5d384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7627770e3a464e43a0df06106b415fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Boost Parameters: {'supplier_name': 2.851248382125411, 'supplier_type': 0.024230484645799355, 'risk_level': 1.662058961249682, 'compliance_issues': 1.076786161860066, 'key_terms': 1.9501908069187228, 'past_performance': 0.8608987553236375, 'negotiate_recommendation': 1.2343547407376998, 'supply_chain_disruption': 1.2441531632367004, 'quality_metrics': 0.9323497365827769, 'cost_metrics': 1.9974456205995172}\n",
      "Best MRR Score: 0.9348186031746032\n"
     ]
    }
   ],
   "source": [
    "best_params, best_score = simple_optimize(param_ranges, objective, n_iterations=20)\n",
    "\n",
    "print(\"Best Boost Parameters:\", best_params)\n",
    "print(\"Best MRR Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5858c06a-f10d-4610-a7b8-77c5ff8b0055",
   "metadata": {},
   "source": [
    "This is the optimized search function using the best boost parameters obtained from the optimization step. These parameters are applied to the search function, and it is evaluated using the full ground truth dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e170b464-c6ef-4cbc-b9d0-8931253171aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802b32a01fbb43eca29b6111ffac03b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.93736, 'mrr': 0.9344387936507936}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minsearch_improved(query):\n",
    "    boost = {\n",
    "        'supplier_name': best_params['supplier_name'],\n",
    "        'supplier_type': best_params['supplier_type'],\n",
    "        'risk_level': best_params['risk_level'],\n",
    "        'compliance_issues': best_params['compliance_issues'],\n",
    "        'key_terms': best_params['key_terms'],\n",
    "        'past_performance': best_params['past_performance'],\n",
    "        'negotiate_recommendation': best_params['negotiate_recommendation'],\n",
    "        'supply_chain_disruption': best_params['supply_chain_disruption'],\n",
    "        'quality_metrics': best_params['quality_metrics'],\n",
    "        'cost_metrics': best_params['cost_metrics']\n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "evaluate(ground_truth, lambda q: minsearch_improved(q['question']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc75592-fba1-468c-a768-81fc33645165",
   "metadata": {},
   "source": [
    "Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f003abce-d718-40d0-bc4e-a1c5e03fee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d4a4130-516f-41a7-a7ae-459b911531aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa45375a64204bbfa34f03a72ebeeda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Hit Rate: 0.97296\n",
      "TF-IDF MRR: 0.9553497460317472\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Ensure the text is a string\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        # Additional preprocessing steps like removing punctuation can be added here\n",
    "        return text\n",
    "    return ''\n",
    "\n",
    "# Apply preprocessing\n",
    "df_question['processed_question'] = df_question['question'].apply(preprocess_text)\n",
    "\n",
    "# Prepare TF-IDF Vectorizer with custom settings\n",
    "corpus = df_question['processed_question'].tolist()\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),  # Bi-grams\n",
    "    stop_words='english',  # Use English stop words\n",
    "    sublinear_tf=True  # Sublinear term frequency scaling\n",
    ")\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "def tfidf_search(query, num_results=10):\n",
    "    query_processed = preprocess_text(query)\n",
    "    query_vec = vectorizer.transform([query_processed])\n",
    "    similarities = cosine_similarity(query_vec, X).flatten()\n",
    "    top_indices = np.argsort(similarities)[::-1][:num_results]\n",
    "    return df_question.iloc[top_indices].to_dict(orient='records')\n",
    "\n",
    "def evaluate_tfidf(ground_truth):\n",
    "    relevance_total = []\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = tfidf_search(q['question'])\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n",
    "\n",
    "# Evaluate TF-IDF retrieval approach\n",
    "tfidf_results = evaluate_tfidf(ground_truth)\n",
    "print('TF-IDF Hit Rate:', tfidf_results['hit_rate'])\n",
    "print('TF-IDF MRR:', tfidf_results['mrr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f8e07b5-7794-4176-a8b9-98e928cf7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best one among the the two \n",
    "def compare_methods(ground_truth, best_params):\n",
    "    # Evaluate TF-IDF\n",
    "    tfidf_results = evaluate_tfidf(ground_truth)\n",
    "    \n",
    "    # Evaluate Minsearch\n",
    "    minsearch_results = evaluate(ground_truth, best_params)\n",
    "\n",
    "    print(\"TF-IDF Results:\")\n",
    "    print('Hit Rate:', tfidf_results['hit_rate'])\n",
    "    print('MRR:', tfidf_results['mrr'])\n",
    "\n",
    "    print(\"Minsearch Results:\")\n",
    "    print('Hit Rate:', minsearch_results['hit_rate'])\n",
    "    print('MRR:', minsearch_results['mrr'])\n",
    "\n",
    "    if tfidf_results['mrr'] > minsearch_results['mrr']:\n",
    "        return 'TF-IDF', tfidf_results\n",
    "    else:\n",
    "        return 'Minsearch', minsearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3c6ed1a-a96e-4ac0-a996-2512b7af711e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7232fc3f58145308de48c4731983f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b180e905c7a4f81b38e381665d85027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Results:\n",
      "Hit Rate: 0.97296\n",
      "MRR: 0.9553497460317472\n",
      "Minsearch Results:\n",
      "Hit Rate: 0.93736\n",
      "MRR: 0.9344387936507936\n"
     ]
    }
   ],
   "source": [
    "results = compare_methods(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b747c380-28c5-40e1-8dd7-e568dad15b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TF-IDF', {'hit_rate': 0.97296, 'mrr': 0.9553497460317472})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c1745-3320-4ed8-907e-1c872b95caab",
   "metadata": {},
   "source": [
    "**RAG evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a179961a-83ad-4b9e-a1dd-314b1a9eddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f17517b-959d-48ce-a200-fd684f40ce0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8ab18b4-67c5-4276-95df-6deb2d01e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b232bd-6cb7-4092-94a4-60048a19bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = record['question']\n",
    "answer_llm = rag(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72d688b4-1246-4e1b-8200-8015b276b68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supplier 1 has a high risk level and has had compliance issues with non-compliance with standards.\n"
     ]
    }
   ],
   "source": [
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49608ac4-2542-4c28-849c-625a993dabc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: What is the risk level of Supplier 1 and what compliance issues have they had?\n",
      "Generated Answer: Supplier 1 has a high risk level and has had compliance issues with non-compliance with standards.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39e98d91-4ab6-4f56-a818-475df561d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f153feb1-0068-40ba-8908-007a8c1a0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_question.sample(n=1250, random_state=1)\n",
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "194f57e5-2897-4f60-9598-70cfaebcba38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d78c9d40f9f40268373df004953947c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question) \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "+\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "262948ad-86dc-4b37-9e54-3b5e34a113c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4531ea5-e9d6-4433-950b-8f9140b81a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.6760\n",
       "NON_RELEVANT       0.3088\n",
       "PARTLY_RELEVANT    0.0152\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a129b86-5441-47c3-9e6d-b9c6cf9b71d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv(r'/workspaces/Supply-Chain-Management/Data/Evaluation/rag-eval-Llama3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb8419cf-38e3-4f09-a102-c3cfef7eaae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4313732c8cb40a3810deb22996cb01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "evaluations_gpt4o = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question, model='gemma-7b-it') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    \n",
    "    evaluations_gpt4o.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5520669d-359b-4062-aabf-a1b574f51f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eval = pd.DataFrame(evaluations_gpt4o, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66fe34b5-ed2a-4700-9526-f85743beec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eval.to_csv(r'/workspaces/Supply-Chain-Management/Data/Evaluation/rag-eval-gemma-7b-it.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6eb9b5ce-93f4-48dd-8cb8-aac561e40203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463cede287ed4bf48c73e4243038cc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a198e4a5f2a443a80e6e94674b1ac3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa80066727f4ddba068deb0b27d898f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a273e28917854d0582a9f5b6697f6b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71718f4a079a4a32961935a4d0025bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "100%|| 1250/1250 [1:56:06<00:00,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevance\n",
      "PARTLY_RELEVANT    0.5792\n",
      "RELEVANT           0.2936\n",
      "NON_RELEVANT       0.1272\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Initialize the classifier\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"distilbert-base-uncased\")\n",
    "\n",
    "evaluations = []\n",
    "\n",
    "# Evaluation loop\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question) \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "    \n",
    "    # Use the classifier to evaluate relevance\n",
    "    result = classifier(\n",
    "        sequences=prompt,\n",
    "        candidate_labels=[\"NON_RELEVANT\", \"PARTLY_RELEVANT\", \"RELEVANT\"]\n",
    "    )\n",
    "    \n",
    "    # Process the evaluation result\n",
    "    evaluation = {\n",
    "        \"Relevance\": result['labels'][0],\n",
    "        \"Explanation\": f\"Score: {result['scores'][0]}\"\n",
    "    }\n",
    "    \n",
    "    evaluations.append((record, answer_llm, evaluation))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb11446f-c72d-435f-8a2c-3d3343990096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevance\n",
      "PARTLY_RELEVANT    0.5792\n",
      "RELEVANT           0.2936\n",
      "NON_RELEVANT       0.1272\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert evaluations to DataFrame\n",
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['score'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']\n",
    "\n",
    "# Display relevance counts\n",
    "print(df_eval.relevance.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4dadf999-b7ee-4397-97b2-f679ed0ac4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yes, the supplier has experienced supply chain...</td>\n",
       "      <td>S0956</td>\n",
       "      <td>Does the supplier have any supply chain disrup...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>Score: 0.33338719606399536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Supplier 929 is not mentioned in the provided ...</td>\n",
       "      <td>S0929</td>\n",
       "      <td>How has Supplier 929 performed in the past?</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>Score: 0.33344629406929016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Supplier 1270 is not mentioned in the provided...</td>\n",
       "      <td>S1270</td>\n",
       "      <td>How has Supplier 1270 performed in the past?</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>Score: 0.333422988653183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Supplier 1493 is not mentioned in the provided...</td>\n",
       "      <td>S1493</td>\n",
       "      <td>How has Supplier 1493 performed in the past an...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>Score: 0.3334648907184601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Supplier 370 is not present in the provided da...</td>\n",
       "      <td>S0370</td>\n",
       "      <td>How has Supplier 370 performed in the past and...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>Score: 0.3334074914455414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>The total cost of the products supplied by Sup...</td>\n",
       "      <td>S2115</td>\n",
       "      <td>What is the total cost of the products supplie...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>Score: 0.3334018588066101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>The cost metrics for the contract with Supplie...</td>\n",
       "      <td>S0129</td>\n",
       "      <td>What are the cost metrics for the contract wit...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>Score: 0.3334263563156128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>Supplier 1955 is not mentioned in the provided...</td>\n",
       "      <td>S1955</td>\n",
       "      <td>How has Supplier 1955 performed in the past an...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>Score: 0.33346980810165405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>Supplier 1586, which is a Retailer, has a high...</td>\n",
       "      <td>S1586</td>\n",
       "      <td>How has Supplier 1586 performed in the past an...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>Score: 0.3335300385951996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>Supplier 977 has a high risk level, with compl...</td>\n",
       "      <td>S0977</td>\n",
       "      <td>How has Supplier 977 performed in the past and...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>Score: 0.33342501521110535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 answer     id  \\\n",
       "6     Yes, the supplier has experienced supply chain...  S0956   \n",
       "7     Supplier 929 is not mentioned in the provided ...  S0929   \n",
       "14    Supplier 1270 is not mentioned in the provided...  S1270   \n",
       "16    Supplier 1493 is not mentioned in the provided...  S1493   \n",
       "21    Supplier 370 is not present in the provided da...  S0370   \n",
       "...                                                 ...    ...   \n",
       "1194  The total cost of the products supplied by Sup...  S2115   \n",
       "1218  The cost metrics for the contract with Supplie...  S0129   \n",
       "1223  Supplier 1955 is not mentioned in the provided...  S1955   \n",
       "1232  Supplier 1586, which is a Retailer, has a high...  S1586   \n",
       "1246  Supplier 977 has a high risk level, with compl...  S0977   \n",
       "\n",
       "                                               question     relevance  \\\n",
       "6     Does the supplier have any supply chain disrup...  NON_RELEVANT   \n",
       "7           How has Supplier 929 performed in the past?  NON_RELEVANT   \n",
       "14         How has Supplier 1270 performed in the past?  NON_RELEVANT   \n",
       "16    How has Supplier 1493 performed in the past an...  NON_RELEVANT   \n",
       "21    How has Supplier 370 performed in the past and...  NON_RELEVANT   \n",
       "...                                                 ...           ...   \n",
       "1194  What is the total cost of the products supplie...  NON_RELEVANT   \n",
       "1218  What are the cost metrics for the contract wit...  NON_RELEVANT   \n",
       "1223  How has Supplier 1955 performed in the past an...  NON_RELEVANT   \n",
       "1232  How has Supplier 1586 performed in the past an...  NON_RELEVANT   \n",
       "1246  How has Supplier 977 performed in the past and...  NON_RELEVANT   \n",
       "\n",
       "                           score  \n",
       "6     Score: 0.33338719606399536  \n",
       "7     Score: 0.33344629406929016  \n",
       "14      Score: 0.333422988653183  \n",
       "16     Score: 0.3334648907184601  \n",
       "21     Score: 0.3334074914455414  \n",
       "...                          ...  \n",
       "1194   Score: 0.3334018588066101  \n",
       "1218   Score: 0.3334263563156128  \n",
       "1223  Score: 0.33346980810165405  \n",
       "1232   Score: 0.3335300385951996  \n",
       "1246  Score: 0.33342501521110535  \n",
       "\n",
       "[159 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval[df_eval.relevance == 'NON_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc683d93-3b29-4c6a-a4e8-89b3a4ec4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv(r'/workspaces/Supply-Chain-Management/Data/Evaluation/rag-eval-distilbert.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
