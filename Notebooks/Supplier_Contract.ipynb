{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9b16e8-270c-4400-a05b-8ff32a69a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d218b60-eebb-4321-90a2-44a7301f88f7",
   "metadata": {},
   "source": [
    "**INGESTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b827ed-d3b7-47fc-ad29-b48a15dcba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"/workspaces/Supply-Chain-Management/Data/supplier_contracts_dataset.csv\")\n",
    "df = df.replace({np.nan: None})\n",
    "# Rename columns to remove spaces\n",
    "# df.columns = [col.replace(' ', '_') for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb664984-a7ef-4200-b6b5-3e4038f6141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = df.columns.str.lower()\n",
    "# df.to_csv(r\"/workspaces/Supply-Chain-Management/Data/supplier_contracts_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4aa868-e50f-42a6-83c1-edad05481382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['supplier_id', 'supplier_name', 'supplier_type', 'risk_level',\n",
       "       'compliance_issues', 'key_terms', 'past_performance',\n",
       "       'negotiate_recommendation', 'supply_chain_disruption',\n",
       "       'quality_metrics', 'cost_metrics'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0882f38e-bfb0-4a6d-8e86-b800e487995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.rename(columns={'supplier_id':'id'})\n",
    "# # Convert only the relevant text-based fields to string\n",
    "text_fields = ['supplier_name', 'supplier_type', 'risk_level',\n",
    "       'compliance_issues', 'key_terms', 'past_performance',\n",
    "       'negotiate_recommendation', 'supply_chain_disruption',\n",
    "       'quality_metrics', 'cost_metrics']\n",
    "\n",
    "# Ensure the specified text fields are strings\n",
    "for field in text_fields:\n",
    "    df[field] = df[field].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72f92f7-1a8a-4269-8b50-73344ed859c7",
   "metadata": {},
   "source": [
    "**Indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6183ad8-eecb-4b0c-89d5-88e50fcd868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = df.columns.str.lower()\n",
    "# df.to_csv(r\"/workspaces/Supply-Chain-Management/Data/supplier_contracts_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a10368-dd4e-4f83-b5c1-0188e0a964d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300178f7-1cb6-46de-8d96-5375400164ea",
   "metadata": {},
   "source": [
    "Get top 10 list of high risk level contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43b9cd5b-c404-476c-9390-2bf2f2dc600f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'S0430', 'supplier_name': 'Supplier 430', 'supplier_type': 'Service Provider', 'risk_level': 'High', 'compliance_issues': 'None', 'key_terms': '45-day payment, 10-day delivery', 'past_performance': 'Poor', 'negotiate_recommendation': 'Adjust delivery schedules, Include compliance monitoring, Include penalty clauses for late delivery', 'supply_chain_disruption': 'Yes', 'quality_metrics': '4.22% defect rate, Meets standards', 'cost_metrics': '$69.97/unit, $6563.98 total cost'}\n",
      "{'id': 'S1311', 'supplier_name': 'Supplier 1311', 'supplier_type': 'Manufacturer', 'risk_level': 'High', 'compliance_issues': 'Non-Compliance with Standards', 'key_terms': '45-day payment, 10-day delivery', 'past_performance': 'Poor', 'negotiate_recommendation': 'Adjust delivery schedules, Include compliance monitoring, Include penalty clauses for late delivery', 'supply_chain_disruption': 'Yes', 'quality_metrics': '4.61% defect rate, Meets standards', 'cost_metrics': '$52.85/unit, $6165.72 total cost'}\n",
      "{'id': 'S0801', 'supplier_name': 'Supplier 801', 'supplier_type': 'Retailer', 'risk_level': 'High', 'compliance_issues': 'Late Delivery', 'key_terms': '60-day payment, 7-day delivery', 'past_performance': 'Good', 'negotiate_recommendation': 'Seek alternative suppliers, Include penalty clauses for late delivery, Adjust delivery schedules', 'supply_chain_disruption': 'No', 'quality_metrics': '2.1% defect rate, Meets standards', 'cost_metrics': '$55.48/unit, $6206.18 total cost'}\n",
      "{'id': 'S1855', 'supplier_name': 'Supplier 1855', 'supplier_type': 'Retailer', 'risk_level': 'High', 'compliance_issues': 'Late Delivery', 'key_terms': '30-day payment, 5-day delivery', 'past_performance': 'Fair', 'negotiate_recommendation': 'Seek alternative suppliers, Include penalty clauses for late delivery, Include compliance monitoring', 'supply_chain_disruption': 'No', 'quality_metrics': '3.79% defect rate, Meets standards', 'cost_metrics': '$57.42/unit, $6714.71 total cost'}\n",
      "{'id': 'S0441', 'supplier_name': 'Supplier 441', 'supplier_type': 'Manufacturer', 'risk_level': 'High', 'compliance_issues': 'None', 'key_terms': '45-day payment, 10-day delivery', 'past_performance': 'Excellent', 'negotiate_recommendation': 'Adjust delivery schedules, Seek alternative suppliers, Include penalty clauses for late delivery', 'supply_chain_disruption': 'No', 'quality_metrics': '1.89% defect rate, Meets standards', 'cost_metrics': '$56.72/unit, $5523.25 total cost'}\n",
      "{'id': 'S1844', 'supplier_name': 'Supplier 1844', 'supplier_type': 'Distributor', 'risk_level': 'High', 'compliance_issues': 'None', 'key_terms': '45-day payment, 10-day delivery', 'past_performance': 'Good', 'negotiate_recommendation': 'Include compliance monitoring, Include penalty clauses for late delivery, Seek alternative suppliers', 'supply_chain_disruption': 'Yes', 'quality_metrics': '3.77% defect rate, Meets standards', 'cost_metrics': '$64.17/unit, $6985.11 total cost'}\n",
      "{'id': 'S1842', 'supplier_name': 'Supplier 1842', 'supplier_type': 'Distributor', 'risk_level': 'High', 'compliance_issues': 'None', 'key_terms': '60-day payment, 7-day delivery', 'past_performance': 'Fair', 'negotiate_recommendation': 'Include penalty clauses for late delivery, Adjust delivery schedules, Seek alternative suppliers', 'supply_chain_disruption': 'Yes', 'quality_metrics': '2.86% defect rate, Meets standards', 'cost_metrics': '$56.6/unit, $5890.59 total cost'}\n",
      "{'id': 'S0438', 'supplier_name': 'Supplier 438', 'supplier_type': 'Distributor', 'risk_level': 'High', 'compliance_issues': 'Non-Compliance with Standards', 'key_terms': '30-day payment, 5-day delivery', 'past_performance': 'Good', 'negotiate_recommendation': 'Seek alternative suppliers, Include compliance monitoring, Adjust delivery schedules', 'supply_chain_disruption': 'Yes', 'quality_metrics': '1.61% defect rate, Meets standards', 'cost_metrics': '$54.41/unit, $5361.45 total cost'}\n",
      "{'id': 'S1840', 'supplier_name': 'Supplier 1840', 'supplier_type': 'Manufacturer', 'risk_level': 'High', 'compliance_issues': 'Non-Compliance with Standards', 'key_terms': '60-day payment, 7-day delivery', 'past_performance': 'Fair', 'negotiate_recommendation': 'Include compliance monitoring, Include penalty clauses for late delivery, Seek alternative suppliers', 'supply_chain_disruption': 'No', 'quality_metrics': '4.95% defect rate, Meets standards', 'cost_metrics': '$60.63/unit, $5250.09 total cost'}\n",
      "{'id': 'S0495', 'supplier_name': 'Supplier 495', 'supplier_type': 'Service Provider', 'risk_level': 'High', 'compliance_issues': 'Late Delivery', 'key_terms': '45-day payment, 10-day delivery', 'past_performance': 'Poor', 'negotiate_recommendation': 'Include penalty clauses for late delivery, Include compliance monitoring, Seek alternative suppliers', 'supply_chain_disruption': 'No', 'quality_metrics': '1.67% defect rate, Meets standards', 'cost_metrics': '$69.61/unit, $6142.64 total cost'}\n"
     ]
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "# Create an index\n",
    "index = minsearch.Index(\n",
    "    text_fields=text_fields,\n",
    "    keyword_fields=[]\n",
    ")\n",
    "\n",
    "# Fit the index with the documents\n",
    "index.fit(documents)\n",
    "\n",
    "# Example search query\n",
    "query = \"high risk level\"\n",
    "results = index.search(query, num_results=10)\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c74c41-7f4e-4e5b-b043-cb561d3545ff",
   "metadata": {},
   "source": [
    "*Get the Contract types that has high risk and their count*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884b4c83-5084-4261-8294-d96ccc7d5f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each supplier type with high risk level:\n",
      "Manufacturer: 201\n",
      "Service Provider: 219\n",
      "Retailer: 197\n",
      "Distributor: 198\n"
     ]
    }
   ],
   "source": [
    "import minsearch\n",
    "from collections import Counter\n",
    "# Create an index\n",
    "index = minsearch.Index(\n",
    "    text_fields=text_fields,\n",
    "    keyword_fields=['risk_level']\n",
    ")\n",
    "\n",
    "# Fit the index with the documents\n",
    "index.fit(documents)\n",
    "\n",
    "# Perform the search for high-risk level contracts\n",
    "filter_dict = {'risk_level': 'High'}\n",
    "results = index.search(query='high risk level', filter_dict=filter_dict, num_results=len(documents))\n",
    "\n",
    "# Extract and print contract types with high risk level\n",
    "high_risk_contract_types = [result['supplier_type'] for result in results]\n",
    "\n",
    "# Count the occurrences of each contract type\n",
    "contract_type_counts = Counter(high_risk_contract_types)\n",
    "\n",
    "# Print the count of each contract type\n",
    "print(\"Count of each supplier type with high risk level:\")\n",
    "for contract_type, count in contract_type_counts.items():\n",
    "    print(f\"{contract_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cba7a3d-375a-446f-99f1-784b93b04861",
   "metadata": {},
   "source": [
    "**RAG flow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4215677c-21b6-421a-a293-51059466e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55dcc07c-a334-4093-a931-a8d36579dc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supplier Types:\n",
      "- Manufacturer\n",
      "- Retailer\n",
      "- Distributor\n",
      "- Service Provider\n",
      "\n",
      "Quality Metrics:\n",
      "- Defect Rate: 1.48%, 1.76%, 1.81%, 2.45%, 3.01%, 3.43%, 3.84%, 4.27%, 4.38%, 4.68%\n",
      "- Meets Standards: Yes\n",
      "\n",
      "Supply Chain Disruptions:\n",
      "- Yes\n",
      "- No\n",
      "\n",
      "Negotiation Recommendations:\n",
      "- Seek alternative suppliers\n",
      "- Include penalty clauses for late delivery\n",
      "- Adjust delivery schedules\n",
      "- Include compliance monitoring\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to perform the search on supplier contracts based on query\n",
    "\n",
    "def search(query, filter_dict=None, max_results=10):\n",
    "    # Filter the DataFrame based on risk level (if provided)\n",
    "    if filter_dict:\n",
    "        filtered_df = df[df['risk_level'] == filter_dict.get('risk_level', '')]\n",
    "    else:\n",
    "        filtered_df = df\n",
    "    # Convert the filtered data to a list of dictionaries and limit the number of results\n",
    "    results = filtered_df.to_dict(orient='records')[:max_results]\n",
    "    return results\n",
    "\n",
    "# Function to build a clearer prompt for Groq API\n",
    "def build_clear_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context += (\n",
    "            f\"- **Supplier_Type**: {doc['supplier_type']}\\n\"\n",
    "            f\"  **Supplier_Name**: {doc['supplier_name']}\\n\"\n",
    "            f\"  **Risk_Level**: {doc['risk_level']}\\n\"\n",
    "            f\"  **Compliance_Issues**: {doc['compliance_issues']}\\n\"\n",
    "            f\"  **Key_Terms**: {doc['key_terms']}\\n\"\n",
    "            f\"  **Negotiate_Recommendation**: {doc['negotiate_recommendation']}\\n\"\n",
    "            f\"  **Quality_Metrics**: {doc['quality_metrics']}\\n\"\n",
    "            f\"  **Past_Performance**: {doc['past_performance']}\\n\"\n",
    "            f\"  **Supply_Chain_Disruption**: {doc['supply_chain_disruption']}\\n\"\n",
    "            f\"  **Cost_Metrics**: {doc['cost_metrics']}\\n\\n\"\n",
    "        )\n",
    "    \n",
    "    prompt = (\n",
    "        f\"QUESTION: {query}\\n\\n\"\n",
    "        f\"CONTEXT:\\n{context}\"\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Function to call the LLM (Groq API)\n",
    "def llm(prompt, model='Llama3-groq-70b-8192-tool-use-preview'):\n",
    "    # Assuming client is the Groq API client instance\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Function to perform the full RAG (Retrieve and Generate) process\n",
    "def rag(query, model='Llama3-groq-70b-8192-tool-use-preview'):\n",
    "    # Search for high-risk contracts (you can modify filter_dict based on needs)\n",
    "    search_results = search(query, filter_dict={'risk_level': 'High'})\n",
    "    \n",
    "    # Build the prompt using the search results\n",
    "    prompt = build_clear_prompt(query, search_results)\n",
    "    \n",
    "    # Get the LLM response based on the prompt\n",
    "    answer = llm(prompt, model=model)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "question = \"Give supplier types, quality metrics, supply chain disruptions, and their negotiation recommendations for high-risk contracts\"\n",
    "answer = rag(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da304f86-6d92-490a-8769-2aa75162d14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Risk-Based Queries\n",
      "Supplier 6, Supplier 8, Supplier 12, Supplier 14, Supplier 15, Supplier 26, Supplier 28, Supplier 32, Supplier 38, and Supplier 40 all have non-compliance issues regardless of risk level.\n",
      "\n",
      "## Compliance & Legal Queries:\n",
      "Based on the provided data, the suppliers where compliance monitoring is recommended are:\n",
      "\n",
      "1. Supplier 12\n",
      "2. Supplier 40\n",
      "\n",
      "## Cost and Financial Metrics:\n",
      "Supplier 6, Supplier 8, Supplier 12, Supplier 14, Supplier 15, Supplier 26, Supplier 28, Supplier 32, Supplier 38, Supplier 40\n",
      "\n",
      "## Contractual Terms and Recommendations:\n",
      "Based on the provided data, the suppliers with penalty clauses for late delivery in their contracts are:\n",
      "\n",
      "1. Supplier 6\n",
      "2. Supplier 8\n",
      "3. Supplier 12\n",
      "4. Supplier 14\n",
      "5. Supplier 15\n",
      "6. Supplier 26\n",
      "7. Supplier 28\n",
      "8. Supplier 32\n",
      "9. Supplier 38\n",
      "10. Supplier 40\n",
      "\n",
      "The associated risks with these suppliers include:\n",
      "\n",
      "1. Supplier 6: High risk due to non-compliance with standards and supply chain disruption.\n",
      "2. Supplier 8: High risk due to non-compliance with standards and supply chain disruption.\n",
      "3. Supplier 12: High risk due to substandard quality and supply chain disruption.\n",
      "4. Supplier 14: High risk due to non-compliance with standards and supply chain disruption.\n",
      "5. Supplier 15: High risk due to non-compliance with standards and no supply chain disruption.\n",
      "6. Supplier 26: High risk due to late delivery and supply chain disruption.\n",
      "7. Supplier 28: High risk due to late delivery and no supply chain disruption.\n",
      "8. Supplier 32: High risk due to non-compliance with standards and no supply chain disruption.\n",
      "9. Supplier 38: High risk due to late delivery and supply chain disruption.\n",
      "10. Supplier 40: High risk due to non-compliance with standards and no supply chain disruption.\n",
      "\n",
      "## Supplier Relationship Queries:\n",
      "The relationship metrics for suppliers with the best past performance scores are as follows:\n",
      "\n",
      "1. Supplier 14 (Service Provider): Excellent past performance, 2.45% defect rate, and $69.82/unit cost.\n",
      "2. Supplier 26 (Distributor): Excellent past performance, 4.27% defect rate, and $65.79/unit cost.\n",
      "3. Supplier 32 (Retailer): Excellent past performance, 1.48% defect rate, and $56.9/unit cost.\n",
      "4. Supplier 38 (Retailer): Excellent past performance, 4.68% defect rate, and $57.93/unit cost.\n",
      "5. Supplier 40 (Retailer): Excellent past performance, 1.76% defect rate, and $66.89/unit cost.\n",
      "\n",
      "## Opportunity and Innovation Queries:\n",
      "Supplier 6, Supplier 8, Supplier 12, Supplier 14, Supplier 15, Supplier 26, Supplier 28, Supplier 32, Supplier 38, and Supplier 40 are suppliers with innovative solutions despite having poor quality metrics.\n",
      "\n",
      "# Custom Queries\n",
      "Based on the provided information, the suppliers with a combination of poor quality metrics, high compliance issues, and good past performance scores are:\n",
      "\n",
      "1. Supplier 6\n",
      "2. Supplier 8\n",
      "3. Supplier 12\n",
      "4. Supplier 14\n",
      "5. Supplier 26\n",
      "6. Supplier 28\n",
      "7. Supplier 32\n",
      "8. Supplier 38\n",
      "9. Supplier 40\n",
      "\n",
      "\n",
      "The patterns between compliance issues and cost metrics in supplier contracts can be observed in the following ways:\n",
      "\n",
      "1. **High Risk Level and Compliance Issues**: All suppliers with a high risk level have compliance issues, either with non-compliance with standards, late delivery, or substandard quality. This indicates that suppliers with higher risk levels are more likely to have compliance issues.\n",
      "\n",
      "2. **Compliance Issues and Cost Metrics**: Suppliers with compliance issues generally have higher cost metrics. For example, Supplier 6 has a high defect rate and higher cost metrics compared to Supplier 32, which has a lower defect rate and lower cost metrics. This suggests that compliance issues may lead to higher costs.\n",
      "\n",
      "3. **Risk Level and Cost Metrics**: Suppliers with a high risk level tend to have higher cost metrics. For instance, Supplier 14 has a high risk level and higher cost metrics compared to Supplier 32, which has a lower risk level and lower cost metrics. This indicates that higher risk levels may result in higher costs.\n",
      "\n",
      "4. **Supplier Type and Cost Metrics**: Retailers tend to have higher cost metrics compared to manufacturers and distributors. This could be due to the nature of their business, as retailers often have higher overhead costs.\n",
      "\n",
      "5. **Negotiation Recommendations**: The negotiation recommendations often include seeking alternative suppliers, adjusting delivery schedules, and including penalty clauses for late delivery. These recommendations are more common for suppliers with compliance issues and higher cost metrics, suggesting that addressing these issues could potentially lower costs.\n",
      "\n",
      "6. **Supply Chain Disruption and Cost Metrics**: Suppliers experiencing supply chain disruptions tend to have higher cost metrics. For example, Supplier 14 has a high risk level, compliance issues, and higher cost metrics, while Supplier 32 has a lower risk level, no compliance issues, and lower cost metrics. This indicates that supply chain disruptions can lead to higher costs.\n",
      "\n",
      "7. **Quality Metrics and Cost Metrics**: Suppliers with higher defect rates tend to have higher cost metrics. For instance, Supplier 6 has a higher defect rate and higher cost metrics compared to Supplier 32, which has a lower defect rate and lower cost metrics. This suggests that improving quality metrics could potentially lower costs.\n",
      "\n",
      "8. **Past Performance and Cost Metrics**: Suppliers with excellent past performance tend to have lower cost metrics. For example, Supplier 32 has excellent past performance and lower cost metrics, while Supplier 6 has good past performance and higher cost metrics. This indicates that suppliers with better past performance may offer more competitive pricing.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n## Risk-Based Queries\")\n",
    "\n",
    "question = \"Which suppliers have the most non-compliance issues, regardless of risk level?\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Compliance & Legal Queries:\")\n",
    "\n",
    "question = \"Identify suppliers where compliance monitoring is recommended.\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Cost and Financial Metrics:\")\n",
    "\n",
    "question = \"List suppliers that offer the best cost metrics but are classified as high risk.\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Contractual Terms and Recommendations:\")\n",
    "\n",
    "question = \"Which suppliers have penalty clauses for late delivery in their contracts, and what are the associated risks?\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Supplier Relationship Queries:\")\n",
    "\n",
    "question = \"What are the relationship metrics for suppliers with the best past performance scores?\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n## Opportunity and Innovation Queries:\")\n",
    "\n",
    "question = \"Identify suppliers with innovative solutions despite having poor quality metrics.\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n# Custom Queries\")\n",
    "\n",
    "question = \"Show me all suppliers with a combination of poor quality metrics, high compliance issues, and good past performance scores.\"\n",
    "answer = rag(question)\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "question = \"What are the patterns between compliance issues and cost metrics in supplier contracts?\"\n",
    "answer = rag(question)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f87d9c7-7030-4aa2-85c4-475f38ff510c",
   "metadata": {},
   "source": [
    "**Retrieval Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbfa8de3-429b-470e-9ddb-ce3939eaec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9e0a5b5-ba46-425c-9bdd-f4743dd52fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_csv(r'/workspaces/Supply-Chain-Management/Data/ground-truth-retrieval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d80cba8-22c8-4707-987e-d3cd2d350788",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8370ef3f-0e1a-40a6-bac8-31a5d56cc9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbd9785de534134b41d4b81ab0de64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.86392, 'mrr': 0.850265492063492}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score += 1 / (rank + 1)\n",
    "                break  \n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e91d819-281f-428f-8f67-1209b44d8ea4",
   "metadata": {},
   "source": [
    "**Best Retrieval Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b749d-08f0-4bb7-9781-06be625dd350",
   "metadata": {},
   "source": [
    "Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ded4ca2a-4f0f-441d-859f-42f0894aded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_validation, df_test = train_test_split(df_question, test_size=0.5, random_state=42)\n",
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4514d762-dbfa-411e-af2c-dcdb34b9d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},  # Adjust filters if needed\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f31c9-45a1-4d33-91ce-a6983a765432",
   "metadata": {},
   "source": [
    "This function interacts with your search index. If no boost parameters are provided, it defaults to an empty dictionary. It returns the top 10 search results based on the query and the optional boost parameters. The boost_dict modifies the importance of specific fields during the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7a19140-e2eb-4f3f-9ebe-8c4575242a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_ranges = {\n",
    "    'supplier_name': (0.0, 3.0),\n",
    "    'supplier_type': (0.0, 3.0),\n",
    "    'risk_level': (0.0, 3.0),\n",
    "    'compliance_issues': (0.0, 3.0),\n",
    "    'key_terms': (0.0, 3.0),\n",
    "    'past_performance': (0.0, 3.0),\n",
    "    'negotiate_recommendation': (0.0, 3.0),\n",
    "    'supply_chain_disruption': (0.0, 3.0),\n",
    "    'quality_metrics': (0.0, 3.0),\n",
    "    'cost_metrics': (0.0, 3.0),\n",
    "}\n",
    "\n",
    "def objective(boost_params):\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q['question'], boost_params)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    return results['mrr']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f162a7b-ca03-4e66-8eb3-54f9e12c8b2b",
   "metadata": {},
   "source": [
    "This dictionary defines the range of values that each parameter can take during optimization. The values indicate how much weight or importance is assigned to each of these fields when retrieving results from the search index.\n",
    "\n",
    "The function evaluates the effectiveness of a particular set of boost parameters. It does so by calling minsearch_search with the boost parameters and calculating the Mean Reciprocal Rank (MRR) over the validation set (gt_val). The higher the MRR score, the better the ranking of relevant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b4c8acc-86ef-4936-bf6e-2a50224c0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def simple_optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf')  # Assuming we're minimizing. Use float('-inf') if maximizing.\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random parameters\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                current_params[param] = random.randint(min_val, max_val)\n",
    "            else:\n",
    "                current_params[param] = random.uniform(min_val, max_val)\n",
    "        \n",
    "        # Evaluate the objective function\n",
    "        current_score = objective_function(current_params)\n",
    "        \n",
    "        # Update best if current is better\n",
    "        if current_score > best_score:  # Change to > if maximizing\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "    \n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f54d253-420a-4f52-a92c-f2e55cb0617a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274b99e269a54e1f9dd5abfe7f56f277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9eb30fea4f74512ae053b31732166e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29cc64906f244d7ca6214ef14b7d6fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589f4ac758474e97805ed13939479d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fb43dd9b384231b1ab7b5b73322cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7314a72141e44fd69ae24ae11cd29161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e02df04894478799c225cf5fb9f9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01512e006f304836b2187d188000004f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc7469cceb046e2872dd4200e6ff23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2fa8bf0db04268aa95c4dd44789aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b96153b781f4232a42b05aa68e105fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5c3811ac8a4247a93147093447fae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ac82592b1c4ac5bbeea47144954e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84fa35b13784c97beb20427afb10a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6614432ae49a437ea322c1d54c81a197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9dc7a8e50241a5bf9d0821e298b003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312647b56f2c405fa7ed8002674b6114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1609afb7e2b64a099cd4382d0c5dca00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f7d2e59f5e454ca5aff0a273c65c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabf6c6a9e6c4c27ae700d45f744a366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Boost Parameters: {'supplier_name': 2.1921846312519975, 'supplier_type': 0.2878441236857807, 'risk_level': 2.474645775533791, 'compliance_issues': 0.024174071653687346, 'key_terms': 1.4890132005384054, 'past_performance': 0.31249733837519666, 'negotiate_recommendation': 0.43671475096549994, 'supply_chain_disruption': 0.5198756814001602, 'quality_metrics': 0.3164637012196919, 'cost_metrics': 1.898103749659531}\n",
      "Best MRR Score: 0.9349972698412699\n"
     ]
    }
   ],
   "source": [
    "best_params, best_score = simple_optimize(param_ranges, objective, n_iterations=20)\n",
    "\n",
    "print(\"Best Boost Parameters:\", best_params)\n",
    "print(\"Best MRR Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5858c06a-f10d-4610-a7b8-77c5ff8b0055",
   "metadata": {},
   "source": [
    "This is the optimized search function using the best boost parameters obtained from the optimization step. These parameters are applied to the search function, and it is evaluated using the full ground truth dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e170b464-c6ef-4cbc-b9d0-8931253171aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0436e64996248fead0e139eede2c271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.93744, 'mrr': 0.9347209206349206}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minsearch_improved(query):\n",
    "    boost = {\n",
    "        'supplier_name': best_params['supplier_name'],\n",
    "        'supplier_type': best_params['supplier_type'],\n",
    "        'risk_level': best_params['risk_level'],\n",
    "        'compliance_issues': best_params['compliance_issues'],\n",
    "        'key_terms': best_params['key_terms'],\n",
    "        'past_performance': best_params['past_performance'],\n",
    "        'negotiate_recommendation': best_params['negotiate_recommendation'],\n",
    "        'supply_chain_disruption': best_params['supply_chain_disruption'],\n",
    "        'quality_metrics': best_params['quality_metrics'],\n",
    "        'cost_metrics': best_params['cost_metrics']\n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "evaluate(ground_truth, lambda q: minsearch_improved(q['question']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc75592-fba1-468c-a768-81fc33645165",
   "metadata": {},
   "source": [
    "Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f003abce-d718-40d0-bc4e-a1c5e03fee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d4a4130-516f-41a7-a7ae-459b911531aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e9858f8b3a4c52981d09cb4253658f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Hit Rate: 0.97296\n",
      "TF-IDF MRR: 0.9553497460317472\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Ensure the text is a string\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        # Additional preprocessing steps like removing punctuation can be added here\n",
    "        return text\n",
    "    return ''\n",
    "\n",
    "# Apply preprocessing\n",
    "df_question['processed_question'] = df_question['question'].apply(preprocess_text)\n",
    "\n",
    "# Prepare TF-IDF Vectorizer with custom settings\n",
    "corpus = df_question['processed_question'].tolist()\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),  # Bi-grams\n",
    "    stop_words='english',  # Use English stop words\n",
    "    sublinear_tf=True  # Sublinear term frequency scaling\n",
    ")\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "def tfidf_search(query, num_results=10):\n",
    "    query_processed = preprocess_text(query)\n",
    "    query_vec = vectorizer.transform([query_processed])\n",
    "    similarities = cosine_similarity(query_vec, X).flatten()\n",
    "    top_indices = np.argsort(similarities)[::-1][:num_results]\n",
    "    return df_question.iloc[top_indices].to_dict(orient='records')\n",
    "\n",
    "def evaluate_tfidf(ground_truth):\n",
    "    relevance_total = []\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = tfidf_search(q['question'])\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n",
    "\n",
    "# Evaluate TF-IDF retrieval approach\n",
    "tfidf_results = evaluate_tfidf(ground_truth)\n",
    "print('TF-IDF Hit Rate:', tfidf_results['hit_rate'])\n",
    "print('TF-IDF MRR:', tfidf_results['mrr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f8e07b5-7794-4176-a8b9-98e928cf7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best one among the the two \n",
    "def compare_methods(ground_truth, best_params):\n",
    "    # Evaluate TF-IDF\n",
    "    tfidf_results = evaluate_tfidf(ground_truth)\n",
    "    \n",
    "    # Evaluate Minsearch\n",
    "    minsearch_results = evaluate(ground_truth, best_params)\n",
    "\n",
    "    print(\"TF-IDF Results:\")\n",
    "    print('Hit Rate:', tfidf_results['hit_rate'])\n",
    "    print('MRR:', tfidf_results['mrr'])\n",
    "\n",
    "    print(\"Minsearch Results:\")\n",
    "    print('Hit Rate:', minsearch_results['hit_rate'])\n",
    "    print('MRR:', minsearch_results['mrr'])\n",
    "\n",
    "    if tfidf_results['mrr'] > minsearch_results['mrr']:\n",
    "        return 'TF-IDF', tfidf_results\n",
    "    else:\n",
    "        return 'Minsearch', minsearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3c6ed1a-a96e-4ac0-a996-2512b7af711e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae32b9bcbcc042d88f7dc8b618c498ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fac5f708bb4badac95614cf71e8e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Results:\n",
      "Hit Rate: 0.97296\n",
      "MRR: 0.9553497460317472\n",
      "Minsearch Results:\n",
      "Hit Rate: 0.93744\n",
      "MRR: 0.9347209206349206\n"
     ]
    }
   ],
   "source": [
    "results = compare_methods(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b747c380-28c5-40e1-8dd7-e568dad15b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TF-IDF', {'hit_rate': 0.97296, 'mrr': 0.9553497460317472})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c1745-3320-4ed8-907e-1c872b95caab",
   "metadata": {},
   "source": [
    "**RAG evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a179961a-83ad-4b9e-a1dd-314b1a9eddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f17517b-959d-48ce-a200-fd684f40ce0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8ab18b4-67c5-4276-95df-6deb2d01e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9b232bd-6cb7-4092-94a4-60048a19bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = record['question']\n",
    "answer_llm = rag(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72d688b4-1246-4e1b-8200-8015b276b68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supplier 1 has a high risk level and has had compliance issues with non-compliance with standards.\n"
     ]
    }
   ],
   "source": [
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49608ac4-2542-4c28-849c-625a993dabc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: What is the risk level of Supplier 1 and what compliance issues have they had?\n",
      "Generated Answer: Supplier 1 is not mentioned in the provided context.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39e98d91-4ab6-4f56-a818-475df561d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f153feb1-0068-40ba-8908-007a8c1a0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_question.sample(n=1250, random_state=1)\n",
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "194f57e5-2897-4f60-9598-70cfaebcba38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d78c9d40f9f40268373df004953947c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question) \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "+\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "262948ad-86dc-4b37-9e54-3b5e34a113c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4531ea5-e9d6-4433-950b-8f9140b81a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.6760\n",
       "NON_RELEVANT       0.3088\n",
       "PARTLY_RELEVANT    0.0152\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a129b86-5441-47c3-9e6d-b9c6cf9b71d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eval.to_csv(r'/workspaces/Supply-Chain-Management/Data/Evaluation/rag-eval-Llama3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df91fcf2-4165-4e64-bcf0-314585d48dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv(r'/workspaces/Supply-Chain-Management/Data/Evaluation/rag-eval-Llama3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "953b454e-96c2-4d07-930b-6ac386c4fce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Supplier 163 is not mentioned in the provided ...</td>\n",
       "      <td>S0163</td>\n",
       "      <td>Have there been any supply chain disruptions w...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Supplier 961 is not mentioned in the provided ...</td>\n",
       "      <td>S0961</td>\n",
       "      <td>What are the quality and cost metrics for Supp...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Supplier 929 has not been mentioned in the pro...</td>\n",
       "      <td>S0929</td>\n",
       "      <td>How has Supplier 929 performed in the past?</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Supplier 2322 is not listed in the provided co...</td>\n",
       "      <td>S2322</td>\n",
       "      <td>What is the risk level of Supplier 2322?</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Supplier 652 is not mentioned in the provided ...</td>\n",
       "      <td>S0652</td>\n",
       "      <td>Has there been any supply chain disruption wit...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>Supplier 309 is not listed in the provided con...</td>\n",
       "      <td>S0309</td>\n",
       "      <td>What are the quality and cost metrics for Supp...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>Supplier 1855 is not mentioned in the provided...</td>\n",
       "      <td>S1855</td>\n",
       "      <td>How has Supplier 1855 performed in the past an...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>Supplier 1200 is not mentioned in the provided...</td>\n",
       "      <td>S1200</td>\n",
       "      <td>What is the risk level of Supplier 1200?</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>Supplier 263 has not been mentioned in the pro...</td>\n",
       "      <td>S0263</td>\n",
       "      <td>What compliance issues has Supplier 263 faced ...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>Supplier 1139 is not mentioned in the provided...</td>\n",
       "      <td>S1139</td>\n",
       "      <td>What is the risk level of Supplier 1139?</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 answer     id  \\\n",
       "2     Supplier 163 is not mentioned in the provided ...  S0163   \n",
       "5     Supplier 961 is not mentioned in the provided ...  S0961   \n",
       "7     Supplier 929 has not been mentioned in the pro...  S0929   \n",
       "8     Supplier 2322 is not listed in the provided co...  S2322   \n",
       "11    Supplier 652 is not mentioned in the provided ...  S0652   \n",
       "...                                                 ...    ...   \n",
       "1239  Supplier 309 is not listed in the provided con...  S0309   \n",
       "1241  Supplier 1855 is not mentioned in the provided...  S1855   \n",
       "1242  Supplier 1200 is not mentioned in the provided...  S1200   \n",
       "1248  Supplier 263 has not been mentioned in the pro...  S0263   \n",
       "1249  Supplier 1139 is not mentioned in the provided...  S1139   \n",
       "\n",
       "                                               question     relevance  \\\n",
       "2     Have there been any supply chain disruptions w...  NON_RELEVANT   \n",
       "5     What are the quality and cost metrics for Supp...  NON_RELEVANT   \n",
       "7           How has Supplier 929 performed in the past?  NON_RELEVANT   \n",
       "8              What is the risk level of Supplier 2322?  NON_RELEVANT   \n",
       "11    Has there been any supply chain disruption wit...  NON_RELEVANT   \n",
       "...                                                 ...           ...   \n",
       "1239  What are the quality and cost metrics for Supp...  NON_RELEVANT   \n",
       "1241  How has Supplier 1855 performed in the past an...  NON_RELEVANT   \n",
       "1242           What is the risk level of Supplier 1200?  NON_RELEVANT   \n",
       "1248  What compliance issues has Supplier 263 faced ...  NON_RELEVANT   \n",
       "1249           What is the risk level of Supplier 1139?  NON_RELEVANT   \n",
       "\n",
       "                                            explanation  \n",
       "2     The generated answer does not provide any info...  \n",
       "5     The generated answer does not provide any info...  \n",
       "7     The generated answer does not provide any info...  \n",
       "8     The generated answer does not provide any info...  \n",
       "11    The generated answer does not provide any info...  \n",
       "...                                                 ...  \n",
       "1239  The generated answer does not provide any info...  \n",
       "1241  The generated answer does not address the ques...  \n",
       "1242  The generated answer does not provide any info...  \n",
       "1248  The generated answer does not address the ques...  \n",
       "1249  The generated answer does not provide any info...  \n",
       "\n",
       "[386 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_eval[df_eval.relevance == 'NON_RELEVANT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8419cf-38e3-4f09-a102-c3cfef7eaae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d9e89558c04c69897b6fc7aa9211f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "evaluations_gpt4o = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question, model='gemma-7b-it') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    \n",
    "    evaluations_gpt4o.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520669d-359b-4062-aabf-a1b574f51f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eval = pd.DataFrame(evaluations_gpt4o, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674dd11-0da8-4e6f-a36b-50e9f51cba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe34b5-ed2a-4700-9526-f85743beec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv(r'/workspaces/Supply-Chain-Management/Data/Evaluation/rag-eval-gemma-7b-it.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
